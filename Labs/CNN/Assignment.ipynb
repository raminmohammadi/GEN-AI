{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Assignment (Graded): Image Classification with Fashion MNSIT Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to your programming assignment on Convolutional Neural Networks! You will build a Convolutional Neural Network (CNN) to classify images of the MNIST Fashion Dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this assignment, you will build a Convolutional Neural Network (CNN) to classify images from the Fashion MNIST dataset.\n",
    "\n",
    "- This dataset consists of 70,000 grayscale images in 10 categories and is considered to be more challenging than the original MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Only write code when you see any of the below prompts,\n",
    "\n",
    "    ```\n",
    "    # YOUR CODE GOES HERE\n",
    "    # YOUR CODE ENDS HERE\n",
    "    # TODO\n",
    "    ```\n",
    "\n",
    "- Do not modify any other section of the code unless tated otherwise in the comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An overview of the fashion MNIST dataset:\n",
    "\n",
    "- 60,000 training images\n",
    "\n",
    "- 10,000 test images\n",
    "- 10 classes of clothing items\n",
    "- Image size: 28x28 pixels (grayscale)\n",
    "\n",
    "For more information, refer to this link: [Fashion MNIST Dataset](https://github.com/zalandoresearch/fashion-mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Data Preparation**\n",
    "   - Normalize the pixel values\n",
    "   \n",
    "   - Split the data into training and validation sets\n",
    "\n",
    "**2. Model Architecture**\n",
    "   - Design a CNN with at least 2 convolutional layers and 1 dense layer\n",
    "   - Include appropriate activation functions, pooling layers, and a flatten layer\n",
    "\n",
    "**3. Model Compilation**\n",
    "   - Choose an appropriate optimizer and loss function\n",
    "   - Select accuracy as the metric to monitor\n",
    "\n",
    "**4. Model Training**\n",
    "   - Train the model for at least 10 epochs\n",
    "   - Use a validation split to monitor for overfitting\n",
    "\n",
    "**5. Model Evaluation**\n",
    "   - Evaluate the model on the test set\n",
    "   - Plot the training and validation accuracy/loss curves\n",
    "\n",
    "**6. Predictions and Visualization**\n",
    "   - Make predictions on a few test images\n",
    "   - Visualize these images along with their predicted and actual labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from helpers.methods import load_data, detect_and_set_device, display_image_grid, plot_training_history, plot_predictions\n",
    "from tests.test_methods import test_preprocess_data, test_create_model, test_train_model, test_evaluate_model, test_make_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into training and testing sets\n",
    "x_train, y_train, x_test, y_test = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Let's get to know about our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape of the dataset: Testing and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Shape of the data\n",
    "\n",
    "x_train_shape = \n",
    "x_test_shape = \n",
    "y_train_shape = \n",
    "y_test_shape = \n",
    "number_of_classes =\n",
    "\n",
    "\n",
    "print(f\"Training Data Shape: {x_train_shape}\")\n",
    "print(f\"Training Labels Shape: {y_train_shape}\")\n",
    "print(f\"Test Data Shape: {x_test_shape}\")\n",
    "print(f\"Test Labels Shape: {y_test_shape}\")\n",
    "print(f\"Number of Classes: {number_of_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total number of images in each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(y_train))\n",
    "for cls in range(num_classes):\n",
    "  count = 0\n",
    "  # YOUR CODE GOES HERE\n",
    "  \n",
    "  # YOUR CODE ENDS HERE\n",
    "  print(\"Number of images belonging to {} is {}\".format(cls, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Preprocessing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task Hints:**\n",
    "\n",
    "Complete the preprocess_data method.\n",
    "\n",
    "- Convert the pixel values of the training and test data (x_train and x_test) to floating-point numbers and scale them to the range [0, 1].\n",
    "\n",
    "- Ensure that the labels (y_train and y_test) have the correct shape by reshaping them into column vectors (with dimensions (-1, 1))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(x_train, y_train, x_test, y_test):\n",
    "    # Normalize the images to [0, 1] range\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # Ensure labels are in the correct shape\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    print(\"Training data shape:\", x_train.shape)\n",
    "    print(\"Training labels shape:\", y_train.shape)\n",
    "    print(\"Test data shape:\", x_test.shape)\n",
    "    print(\"Test labels shape:\", y_test.shape)\n",
    "    \n",
    "    # Do not change the code below\n",
    "    test_preprocess_data(x_train, y_train, x_test, y_test)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task Hints:**\n",
    "\n",
    "Complete the create_model and compile_model function to define a CNN for image classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layers:\n",
    "\n",
    "- Add two Conv2D layers (32 and 64 filters) with ReLU activation and MaxPooling2D after each.\n",
    "\n",
    "- Flatten the output using Flatten().\n",
    "- Add a fully connected Dense layer with 64 neurons (ReLU), followed by a 10-neuron Dense layer with softmax for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        # YOUR CODE HERE: Define the architecture of the model\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    # Do not change the code below\n",
    "    test_create_model(model)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model:\n",
    "\n",
    "- Use Adam optimizer, sparse categorical crossentropy loss, and accuracy as the metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    \n",
    "    # YOUR CODE HERE: Compile the model\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task Hints:**\n",
    "\n",
    "Complete the train_model function to train the CNN using the provided training data.\n",
    "\n",
    "- Set epochs=10 and validation_split=0.2.\n",
    "\n",
    "- Train the model using model.fit(), providing x_train, y_train, epochs, and validation_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(43)  # for reproducibility\n",
    "tf.random.set_seed(43)  # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, x_train, y_train, runtime_device):\n",
    "    # TODO: Define validation_split and epochs\n",
    "    validation_split = \n",
    "    epochs = \n",
    "    \n",
    "    with tf.device('/' + runtime_device + ':0'):\n",
    "        # YOUR CODE GOES HERE\n",
    "\n",
    "\n",
    "        # YOUR CODE ENDS HERE\n",
    "        \n",
    "        # Do not change the code below\n",
    "        test_train_model(history)\n",
    "        \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task Hints:**\n",
    "\n",
    "Complete the evaluate_model function to test the trained model on the test dataset.\n",
    "\n",
    "- Use model.evaluate() to calculate the loss and accuracy on x_test and y_test.\n",
    "\n",
    "- Print the test accuracy for reference.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_test, y_test, runtime_device):\n",
    "    with tf.device('/' + runtime_device + ':0'):\n",
    "        # YOUR CODE GOES HERE\n",
    "\n",
    "\n",
    "        # YOUR CODE ENDS HERE\n",
    "        \n",
    "        # Do not change the code below\n",
    "        test_evaluate_model(test_loss, test_acc)\n",
    "        \n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Make Predictions with the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task Hints:**\n",
    "\n",
    "Complete the make_predictions function to generate predictions using the trained model on the test dataset.\n",
    "\n",
    "- Use model.predict() to generate predictions on x_test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model, x_test, runtime_device):\n",
    "    with tf.device('/' + runtime_device + ':0'):\n",
    "        # YOUR CODE GOES HERE\n",
    "\n",
    "\n",
    "        # YOUR CODE ENDS HERE\n",
    "        \n",
    "        # Do not change the code below\n",
    "        test_predict_model(predictions)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver Code to run the built pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------- Do not change the code below ----------------#\n",
    "def run_classifier(x_train, y_train, x_test, y_test):\n",
    "    data_dir = 'data'\n",
    "\n",
    "    runtime_device = detect_and_set_device()\n",
    "\n",
    "    x_train, y_train, x_test, y_test = preprocess_data(x_train, y_train, x_test, y_test)\n",
    "\n",
    "    model = create_model()\n",
    "    model = compile_model(model)\n",
    "    history = train_model(model, x_train, y_train, runtime_device)\n",
    "    evaluate_model(model, x_test, y_test, runtime_device)\n",
    "\n",
    "    predictions = make_predictions(model, x_test, runtime_device)\n",
    "    return history, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    history, predictions = run_classifier(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to plot the training history\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to plot the predictions\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "                   'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "plot_predictions(predictions, x_test, y_test, class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
