{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Databases Assignment (Graded): Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to your programming assignment on Vector Databases! You will create a Pinecone Database Instance to store the feature vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this assignemnt, you will develop a machine learning system to extract and store visual features from the Flickr8k dataset using a pre-trained ResNet-50 model in a Pinecone vector database. \n",
    "\n",
    "- The system should efficiently process and store image features to enable fast similarity search and retrieval for downstream computer vision tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Flickr8k dataset consists of:\n",
    "- 8,000 unique images from Flickr\n",
    "- 5 different caption descriptions per image (40,000 total captions)\n",
    "- Images with varying visual content, perspectives, and lighting conditions\n",
    "- Standard image format (.jpg files)\n",
    "\n",
    "Key characteristics:\n",
    "- Training set: 6,000 images\n",
    "- Validation set: 1,000 images\n",
    "- Test set: 1,000 images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information, refer to this link: [Flickr-8k Dataset](https://www.kaggle.com/datasets/dibyansudiptiman/flickr-8k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Feature Extraction Setup**\n",
    "- Initialize and configure the pre-trained ResNet-50 model\n",
    "- Remove the final classification layer to obtain 2048-dimensional feature vectors\n",
    "- Set up Pinecone database with appropriate index configuration\n",
    "\n",
    "2. **Image Processing Pipeline**\n",
    "- Implement image preprocessing functions (resizing, normalization)\n",
    "- Create batch processing mechanism for efficient feature extraction\n",
    "- Handle potential errors and edge cases in image processing\n",
    "\n",
    "3. **Database Integration**\n",
    "- Configure Pinecone connection with proper authentication\n",
    "- Design vector storage schema including metadata\n",
    "- Implement batch upsert functionality for efficient data storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Only write code when you see any of the below prompts,\n",
    "\n",
    "    ```\n",
    "    # YOUR CODE GOES HERE\n",
    "    # YOUR CODE ENDS HERE\n",
    "    # TODO\n",
    "    ```\n",
    "\n",
    "- Do not modify any other section of the code unless tated otherwise in the comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from dataclasses import dataclass\n",
    "import os\n",
    "import requests\n",
    "import tarfile\n",
    "import zipfile\n",
    "from helpers.methods import download_dataset, verify_dataset, visualize_sample_images, visualize_feature_distribution, visualize_pinecone_results\n",
    "from tests.test_methods import test_initialize_feature_extractor, test_setup_pinecone, test_batch_process_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Setup the configurations(Do it iteratively while you traverse the code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task Hints:**\n",
    "\n",
    "Complete the configuration of the system by setting up the missing fields in the configuration class.\n",
    "\n",
    "- Update **Model configuration** for ResNet50 model (e.g., specify any other required parameters).\n",
    "- Update **Pinecone configuration** with your environment and key settings.\n",
    "\n",
    "- `image_size`: Specify the size of the images for model processing.\n",
    "- `batch_size`: Define the number of images processed in a single batch.\n",
    "\n",
    "Complete the fields marked as \"Your CODE GOES HERE\" with appropriate values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "@dataclass\n",
    "class Config:\n",
    "    # Dataset configuration\n",
    "    # Do not change the code below\n",
    "    data_root: str = 'data'\n",
    "    flickr8k_path: str = 'data/Flickr8k'\n",
    "    image_dir: str = 'data/Flickr8k/Flicker8k_Dataset'\n",
    "    caption_file: str = 'data/Flickr8k/Flickr8k.token.txt'\n",
    "    train_images_file: str = 'data/Flickr8k/Flickr_8k.trainImages.txt'\n",
    "    test_images_file: str = 'data/Flickr8k/Flickr_8k.testImages.txt'\n",
    "    # Do not change the code above\n",
    "    \n",
    "    # Model configuration (For ResNet50) : Your CODE GOES HERE\n",
    "    image_size: tuple = \n",
    "    batch_size: int = \n",
    "    \n",
    "    # Pinecone configuration: Your CODE GOES HERE\n",
    "    pinecone_api_key: str = ''\n",
    "    pinecone_env: str = ''\n",
    "    index_name: str = 'flickr8k-features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize configuration\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and verify dataset: Do not change the code below\n",
    "print(\"Downloading dataset...\")\n",
    "download_dataset(config)\n",
    "\n",
    "if verify_dataset(config):\n",
    "    print(\"Dataset verified successfully!\")\n",
    "else:\n",
    "    raise Exception(\"Dataset verification failed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Loading and getting to know about the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task Hints:**\n",
    "\n",
    "Complete the `load_and_analyze_captions` function to analyze the captions dataset.\n",
    "\n",
    "- **Loading Data**: Ensure the captions file is read correctly using `pd.read_csv()`.\n",
    "- **Image Parsing**: Split the `image_and_caption_id` column on `#` and extract the image filename into a new column called `image`.\n",
    "  - Use `apply()` with a lambda function to achieve this.\n",
    "  \n",
    "#### Analysis Tasks:\n",
    "- Print the total number of captions.\n",
    "- Print the total number of unique images.\n",
    "- Print the average number of captions per image.\n",
    "\n",
    "#### Additional Analysis:\n",
    "- Create a new column `caption_length` to store the length of each caption (in characters).\n",
    "- Create a new column `word_count` to store the number of words in each caption.\n",
    "  - Use `apply()` with a lambda function to count the number of words.\n",
    "\n",
    "#### Visualization:\n",
    "- Create two subplots:\n",
    "  - The first subplot should display the distribution of caption lengths (number of characters).\n",
    "  - The second subplot should display the distribution of word counts (number of words).\n",
    "\n",
    "- Use `sns.histplot()` for visualization.\n",
    "\n",
    "Make sure to handle exceptions during file loading and print the first line of the file if an error occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_analyze_captions(config: Config):\n",
    "    \"\"\"Load and perform EDA on captions\"\"\"\n",
    "    # Read the token file with proper format\n",
    "    try:\n",
    "        df = pd.read_csv(config.caption_file, sep='\\t', header=None, \n",
    "                        names=['image_and_caption_id', 'caption'])\n",
    "        \n",
    "        # Your code goes here\n",
    "        \n",
    "        # Task: Split the 'image_and_caption_id' column on '#' and create a new column 'image' with the image filename\n",
    "        # Hint: Use the apply() function with a lambda function to split the column\n",
    "        df['image'] = \n",
    "        \n",
    "        print(\"\\n## Caption Analysis\")\n",
    "        # Task: Print the total number of captions\n",
    "        print(f\"Total number of captions: {}\")\n",
    "        \n",
    "        # Task: Print the total number of unique images\n",
    "        print(f\"Unique images: {}\")\n",
    "        \n",
    "        # Task: Print the average number of captions per image\n",
    "        print(f\"Average captions per image: {}\")\n",
    "        \n",
    "        # Calculate caption statistics\n",
    "        # Task: Create a new column 'caption_length' with the length of each caption\n",
    "        df['caption_length'] = \n",
    "        \n",
    "        # Task: Create a new column 'word_count' with the number of words in each caption\n",
    "        # Hint: Use the apply() function with a lambda function to split the caption\n",
    "        df['word_count'] = \n",
    "        \n",
    "        # Visualize distributions\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.histplot(data=df['caption_length'], bins=50)\n",
    "        plt.title('Distribution of Caption Lengths')\n",
    "        plt.xlabel('Number of Characters')\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.histplot(data=df['word_count'], bins=30)\n",
    "        plt.title('Distribution of Word Counts')\n",
    "        plt.xlabel('Number of Words')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading captions: {str(e)}\")\n",
    "        print(\"\\nAttempting to read file contents:\")\n",
    "        try:\n",
    "            with open(config.caption_file, 'r', encoding='utf-8') as f:\n",
    "                print(f.readline())  # Print first line to see format\n",
    "        except Exception as read_error:\n",
    "            print(f\"Could not read file: {str(read_error)}\")\n",
    "        raise\n",
    "    \n",
    "    \n",
    "# Load and analyze dataset: Do not change the code below\n",
    "print(\"\\nAnalyzing dataset...\")\n",
    "df = load_and_analyze_captions(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images: Do not change the code below\n",
    "config = Config()\n",
    "visualize_sample_images(config, df, num_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task Hints:**\n",
    "\n",
    "Complete the `initialize_feature_extractor` function to set up the ResNet-50 model for feature extraction.\n",
    "\n",
    "- **Loading the ResNet50 Model**: Load the ResNet50 model with the following parameters:\n",
    "  - `include_top=False`: Exclude the top fully connected layers.\n",
    "  - `weights='imagenet'`: Use pre-trained weights from ImageNet.\n",
    "  - `input_shape=(*config.image_size, 3)`: Set the input shape according to the configured image size.\n",
    "\n",
    "- **Building the Model**:\n",
    "  - Create a Sequential model that includes:\n",
    "    1. The ResNet50 base model.\n",
    "    2. A `GlobalAveragePooling2D` layer for down-sampling the feature maps.\n",
    "\n",
    "- **Model Configuration**:\n",
    "  - Use `tf.keras.Sequential()` to construct the model.\n",
    "  - Use `tf.keras.layers.GlobalAveragePooling2D()` to add the pooling layer.\n",
    "  - The ResNet50 model should be the first layer in the sequence.\n",
    "  - The model should not be compiled or trained at this stage.\n",
    "\n",
    "- **Testing**:\n",
    "  - After setting up the model, it will be tested automatically using `test_initialize_feature_extractor()`. You do not need to change the test code.\n",
    "\n",
    "Ensure the model is returned from the function at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_feature_extractor(config: Config):\n",
    "    \"\"\"Initialize and configure ResNet-50 model\"\"\"\n",
    "    \n",
    "    # Your code goes here\n",
    "    # Task: Load the ResNet50 model with the following parameters:\n",
    "    # - include_top=False\n",
    "    # - weights='imagenet'\n",
    "    # - input_shape=(*config.image_size, 3)\n",
    "    \n",
    "    base_model = \n",
    "    \n",
    "    # Task: Create a Sequential model with the ResNet50 base model and a GlobalAveragePooling2D layer\n",
    "    # Hint: Use tf.keras.Sequential() with a list of layers\n",
    "    # Hint: The GlobalAveragePooling2D layer can be added using tf.keras.layers.GlobalAveragePooling2D()\n",
    "    # Hint: The base model should be the first layer in the list\n",
    "    # Hint: The model should not be compiled or trained\n",
    "    model = \n",
    "    \n",
    "    # Test the model: Do not change the code below\n",
    "    test_initialize_feature_extractor(model, config)\n",
    "    \n",
    "    # Return the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task Hints:**\n",
    "\n",
    "Complete the `preprocess_image` function to prepare an image for feature extraction using the ResNet-50 model.\n",
    "\n",
    "- **Loading the Image**:\n",
    "  - Load the image from the provided file path.\n",
    "  - Resize the image to the target size specified in the `config.image_size`.\n",
    "  - Use `tf.keras.preprocessing.image.load_img()` with the `target_size` parameter to resize the image.\n",
    "\n",
    "- **Converting Image to Array**:\n",
    "  - Convert the loaded image to a NumPy array for further processing.\n",
    "  - Use `tf.keras.preprocessing.image.img_to_array()` to perform the conversion.\n",
    "\n",
    "- **Preprocessing for ResNet-50**:\n",
    "  - Preprocess the image array to match the input format required by ResNet-50.\n",
    "  - Use `tf.keras.applications.resnet50.preprocess_input()` to preprocess the image for ResNet-50.\n",
    "\n",
    "- **Return**:\n",
    "  - Ensure that the function returns the preprocessed image array.\n",
    "\n",
    "Make sure to follow the image preprocessing steps precisely for correct feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Preprocess image for feature extraction\n",
    "def preprocess_image(image_path, config: Config):\n",
    "    \"\"\"Preprocess single image\"\"\"\n",
    "    # Your code goes here\n",
    "    \n",
    "    # Task: Load the image from the file path and resize it to the target size\n",
    "    # Hint: Use tf.keras.preprocessing.image.load_img() with the target_size parameter\n",
    "    \n",
    "    img = \n",
    "    \n",
    "    # Task: Convert the image to a numpy array and preprocess it for the ResNet50 model\n",
    "    # Hint: Use tf.keras.preprocessing.image.img_to_array() and tf.keras.applications.resnet50.preprocess_input()\n",
    "    img_array = \n",
    "    \n",
    "    # Task: Preprocess the image array for the ResNet50 model\n",
    "    # Hint: Use tf.keras.applications.resnet50.preprocess_input()\n",
    "    img_array = \n",
    "    \n",
    "    # Return the preprocessed image array\n",
    "    return img_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task Hints:**\n",
    "\n",
    "Complete the `extract_features` function to extract image features from a random sample of images using the model.\n",
    "\n",
    "- **Sampling Images**:\n",
    "  - A random sample of images is selected from the `config.image_dir`. This part of the code is already provided and should not be changed.\n",
    "  \n",
    "- **Feature Extraction**:\n",
    "  - For each sampled image:\n",
    "    1. **Preprocess the Image**: \n",
    "        - Preprocess each image using the `preprocess_image()` function. \n",
    "        - Ensure the image is correctly processed for the ResNet-50 model.\n",
    "    2. **Predict Features**:\n",
    "        - Use `model.predict()` to extract features from the preprocessed image.\n",
    "        - The input to `model.predict()` must be expanded with `np.expand_dims()` to add a batch dimension.\n",
    "    3. **Store Features**:\n",
    "        - Extracted features should be appended to a list.\n",
    "        - Use `.squeeze()` to remove the unnecessary dimensions from the feature array.\n",
    "\n",
    "- **Error Handling**:\n",
    "  - If any exception occurs while processing an image, print an error message and continue processing the rest of the images.\n",
    "\n",
    "- **Return**:\n",
    "  - Return the features as a NumPy array.\n",
    "\n",
    "The function should iterate through the randomly sampled images and return the extracted feature representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(model, config: Config, num_samples=100):\n",
    "    \"\"\"Extract features from random sample of images using the model\"\"\"\n",
    "    # Get random sample of images: Do not change the code below\n",
    "    image_files = os.listdir(config.image_dir)\n",
    "    np.random.shuffle(image_files)\n",
    "    sample_files = image_files[:num_samples]\n",
    "    \n",
    "    # Your code goes here\n",
    "    \n",
    "    # Task: Extract features from the sample images using the model\n",
    "    # Hint: Preprocess each image using the preprocess_image() function\n",
    "    # Hint: Use model.predict() to extract features from the preprocessed image\n",
    "    # Hint: Append the features to a list\n",
    "    features = []\n",
    "    for img_file in tqdm(sample_files, desc=\"Extracting features\"):\n",
    "        try:\n",
    "            img_path = os.path.join(config.image_dir, img_file)\n",
    "            # YOUR CODE GOES HERE\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_file}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Setting up Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step-by-Step Instructions**:\n",
    "\n",
    "1. **Initialize Pinecone with API Key**:\n",
    "   - Use the API key provided in the `config` to initialize Pinecone.\n",
    "   - **Hint**: Use the `Pinecone(api_key=config.pinecone_api_key)` command to achieve this.\n",
    "\n",
    "2. **Check for Index Existence**:\n",
    "   - Check if the index with the name `config.index_name` already exists in Pinecone.\n",
    "   - **Hint**: Use `pc.list_indexes()` to get a list of existing indexes.\n",
    "   - If the index does not exist, proceed to create one.\n",
    "\n",
    "3. **Create a New Pinecone Index** (if it doesn’t exist):\n",
    "   - If the index doesn't exist, create a new one using the following configuration:\n",
    "     - `name`: Use the index name from `config.index_name`.\n",
    "     - `dimension`: Use `2048` as the feature dimension (since features from ResNet-50 are of size 2048).\n",
    "     - `metric`: Set the metric to `cosine` for similarity search.\n",
    "     - `spec`: Set up the serverless specifications for the index, using AWS as the cloud provider and the region from `config.pinecone_env`.\n",
    "   - **Hint**: Use `pc.create_index()` for creating the new index.\n",
    "\n",
    "4. **Get the Index Object**:\n",
    "   - Whether the index is newly created or already exists, retrieve the index object for further operations.\n",
    "   - **Hint**: Use `pc.Index(config.index_name)` to get the specific index.\n",
    "\n",
    "5. **Test Pinecone Setup**:\n",
    "   - A test function `test_setup_pinecone` is provided to check if everything is set up correctly. You don’t need to modify this part of the code.\n",
    "\n",
    "\n",
    "### Return:\n",
    "\n",
    "- The function returns the initialized index object that will be used for further operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_pinecone(config: Config):\n",
    "    \"\"\"Initialize Pinecone database with new API\"\"\"\n",
    "    try:\n",
    "        # Task: Initialize Pinecone with the API key from the configuration\n",
    "        # Hint: Use Pinecone() with the api_key parameter\n",
    "        pc = \n",
    "        \n",
    "        # Create index if it doesn't exist\n",
    "        if config.index_name not in pc.list_indexes().names():\n",
    "            # Task: Create a new index with the specified name, dimension, metric, and serverless spec\n",
    "            # YOUR CODE GOES HERE\n",
    "            \n",
    "            \n",
    "            print(f\"Created new index: {config.index_name}\")\n",
    "        else:\n",
    "            print(f\"Using existing index: {config.index_name}\")\n",
    "        \n",
    "        # Task: Get the index object for the specified index name\n",
    "        # Hint: Use pc.Index() with the index name\n",
    "        index = \n",
    "        \n",
    "        # Test the Pinecone setup: Do not change the code below\n",
    "        test_setup_pinecone(index, config, pc)\n",
    "        \n",
    "        return index\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error setting up Pinecone: {str(e)}\")\n",
    "        print(\"\\nPlease ensure:\")\n",
    "        print(\"1. You have installed the latest pinecone-client package\")\n",
    "        print(\"2. Your API key is correct\")\n",
    "        print(\"3. You have sufficient permissions\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Process images to store into the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task Hints**\n",
    "\n",
    "- Step 1: Get Unique Images\n",
    "Retrieve unique image names from the DataFrame.\n",
    "\n",
    "- Step 2: Processing Images in Batches\n",
    "Iterate over unique images in increments defined by `config.batch_size`.\n",
    "\n",
    "- Step 3: Get a Batch of Unique Images\n",
    "Extract a batch of unique images using slicing within the loop.\n",
    "\n",
    "- Step 4: Extract Features from the Batch of Images\n",
    "Process each image in the current batch to extract features.\n",
    "\n",
    "- Step 5: Preprocess Image\n",
    "Prepare the image using the `preprocess_image()` function.\n",
    "\n",
    "- Step 6: Extract Features from the Preprocessed Image\n",
    "Use `model.predict()` with `np.expand_dims()` to obtain image features.\n",
    "\n",
    "- Step 7: Get Captions for the Image\n",
    "Retrieve the associated captions for the current image from the DataFrame.\n",
    "\n",
    "- Step 8: Create a Vector Dictionary\n",
    "Construct a dictionary with keys `'id'`, `'values'`, and `'metadata'`.\n",
    "\n",
    "- Step 9: Append the Vector to the List of Vectors\n",
    "Add the vector dictionary to the `vectors` list.\n",
    "\n",
    "- Step 10: Upsert the Batch of Vectors to the Pinecone Index\n",
    "Upsert the prepared batch of vectors into the Pinecone index using `index.upsert()`.\n",
    "\n",
    "- Step 11: Handle Exceptions\n",
    "Implement error handling to catch and report exceptions during processing.\n",
    "\n",
    "- Final Step: Testing the Batch Processing\n",
    "Keep the test code unchanged at the end of the function for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process_images(model, config: Config, df: pd.DataFrame, index):\n",
    "    \"\"\"Process images in batches and store features\"\"\"\n",
    "    \n",
    "    # Get unique images\n",
    "    unique_images = df['image'].unique()\n",
    "    \n",
    "    # Your code goes here\n",
    "    \n",
    "    # Process images in batches\n",
    "    for i in tqdm(range(0, len(unique_images), config.batch_size)):\n",
    "        \n",
    "        # Task: Get a batch of unique images\n",
    "        batch_images = \n",
    "        \n",
    "        # Task: Extract features from the batch of images using the model\n",
    "        \n",
    "        # Task: Create a list of vectors with the image features and metadata\n",
    "        vectors = []\n",
    "        \n",
    "        for img_name in batch_images:\n",
    "            try:\n",
    "                img_path = os.path.join(config.image_dir, img_name)\n",
    "                if not os.path.exists(img_path):\n",
    "                    print(f\"Image not found: {img_path}\")\n",
    "                    continue\n",
    "                \n",
    "                # Task: Preprocess image\n",
    "                # Hint: Use the preprocess_image() function\n",
    "                img_array = \n",
    "                \n",
    "                # Task: Extract features from the preprocessed image\n",
    "                # Hint: Use model.predict() with np.expand_dims() to add a batch dimension\n",
    "                features = \n",
    "                \n",
    "                # Task: Get captions for the image\n",
    "                # Hint: Use the DataFrame to filter captions for the image\n",
    "                captions = \n",
    "                \n",
    "                # Task: Create a vector dictionary with the image features and metadata\n",
    "                # Hint: The vector should have keys 'id', 'values', and 'metadata'\n",
    "                # Hint: The 'values' should be the features squeezed and converted to a list\n",
    "                # Hint: The 'metadata' should include the 'captions' and 'filename\n",
    "                vector = \n",
    "                \n",
    "                \n",
    "                # Task: Append the vector to the list of vectors\n",
    "                \n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_name}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        if vectors:\n",
    "            try:\n",
    "                # Task: Upsert the batch of vectors to the Pinecone index\n",
    "                # Hint: Use the index.upsert() method with the vectors parameter\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error upserting batch to Pinecone: {str(e)}\")\n",
    "                \n",
    "    # Test the batch processing: Do not change the code below\n",
    "    test_batch_process_images(config, df, model, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # Initialize model\n",
    "    print(\"\\nInitializing feature extractor...\")\n",
    "    model = initialize_feature_extractor(config)\n",
    "    \n",
    "    # Extract features\n",
    "    features = extract_features(model, config, num_samples=100)\n",
    "    \n",
    "    # Visualize distributions\n",
    "    if len(features) > 0:\n",
    "        visualize_feature_distribution(features)\n",
    "    else:\n",
    "        print(\"No features were extracted successfully\")\n",
    "    \n",
    "    # Setup Pinecone and process images\n",
    "    print(\"\\nSetting up Pinecone and processing images...\")\n",
    "    index = setup_pinecone(config)\n",
    "    \n",
    "    # Process images\n",
    "    batch_process_images(model, config, df, index)\n",
    "    \n",
    "    print(\"\\nProcessing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not modify the code below\n",
    "# Visualize Pinecone results: Fetches feature vectores for any 5 random images and visualizes them\n",
    "visualize_pinecone_results(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
