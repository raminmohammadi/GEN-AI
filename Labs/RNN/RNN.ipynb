{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "    <h1>Recurrent Neural Networks(RNNs)</h1>\n",
        "</center>"
      ],
      "metadata": {
        "id": "ePTJ548EONuN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Brief Recap\n",
        "\n",
        "Recurrent Neural Networks (RNNs) are a type of artificial neural network designed for processing sequential data, where the output depends not just on the current input but also on previous inputs. This makes them particularly well-suited for tasks like time series forecasting, language modeling, speech recognition, and machine translation. <br>\n",
        "They were introduced in the 1980s. The foundational work on RNNs is attributed to John Hopfield, who introduced the Hopfield Network in 1982, and David Rumelhart, along with Geoffrey Hinton and Ronald J. Williams, who formalized the concept of backpropagation through time (BPTT) in the mid-1980s.\n",
        "\n"
      ],
      "metadata": {
        "id": "6JpLigzlOWIe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNN Architecture Description\n",
        "\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1lGrjS3f-6lj6GGOUTy0JHS-1McYqMd-3' width=500/>\n",
        "\n",
        "1. **Input Layer:** The input to an RNN is typically a sequence of vectors, where each element of the sequence corresponds to one time step. For example, in a sequence of words (like a sentence), each word can be represented as a vector (often a word embedding).\n",
        "2. **Hidden Layer:** The defining feature of an RNN is its hidden state, which acts as a memory of the network. This state is updated at each time step based on the current input and the previous hidden state.\n",
        "3. **Output Layer:** At each time step, the RNN can produce an output, which might be a prediction(e.g., the next word in a sentence), a classification(e.g., positive or negative sentiment of a sentence) or a final output after the whole sequence has been processed(e.g., classifying a video).  \n",
        "4. **Recurrent Loop:** Unlike traditional neural networks, which process inputs independently, RNNs have recurrent connections that loop information back into the network. This loop allows information to flow from one time step to the next."
      ],
      "metadata": {
        "id": "AjzcBTOwOdy5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advantages of RNNs\n",
        "* **Sequential Data Processing:** They can process input data one element at a time while retaining information about previous inputs, making them ideal for tasks where the order of data matters.\n",
        "* **Memory of previous inputs:** Retains past information through hidden states, capturing context and temporal dependencies.\n",
        "* **Parameter Efficiency:** Uses shared weights across time steps, reducing the number of parameters.\n",
        "* **Variable-Length Inputs:** Can handle sequences of different lengths without architectural changes.\n",
        "* **Contextual Understanding:** Captures broader context in tasks like sentiment analysis and question answering."
      ],
      "metadata": {
        "id": "0xKeRJctOiL1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing RNNs with TensorFlow\n",
        "\n",
        "TensorFlow provides an easy way to implement LSTM layers using the `tf.keras.layers.SimpleRNN` class. Here's an overview of the key components:\n",
        "* `units`: Number of neurons in an RNN layer\n",
        "* `input_shape` (`timesteps`, `input_dim`): Defines shape of the input to the RNN.`timesteps` refers to the number of time steps in each input sequence, and `input_dim` refers to the number of features in each time step.\n",
        "* `return_sequences`: Determines whether to return the output for each time step (`True`) or only the final time step's output (`False`).\n",
        "* `activation`: Specifies the activation function for the output layer.\n",
        "\n",
        "For more detailed information, refer to the TensorFlow documentation on [SimpleRNN](https://www.tensorflow.org/api_docs/python/tf/keras/layers/SimpleRNN)."
      ],
      "metadata": {
        "id": "iEu3F362OltO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "EPf7Wq2BN5XU",
        "outputId": "c682c8c3-b829-41f0-b98f-a35f9728b934"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_12\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ simple_rnn_11 (\u001b[38;5;33mSimpleRNN\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │           \u001b[38;5;34m3,050\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │             \u001b[38;5;34m153\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ simple_rnn_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,050</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">153</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,203\u001b[0m (12.51 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,203</span> (12.51 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,203\u001b[0m (12.51 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,203</span> (12.51 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, Input\n",
        "\n",
        "# Define model parameters\n",
        "input_dim = 10  # Number of features in each time step\n",
        "timesteps = 5   # Number of time steps in each sequence\n",
        "num_classes = 3 # Number of output classes\n",
        "\n",
        "# Build the RNN model\n",
        "model = Sequential()\n",
        "\n",
        "# Add an RNN layer\n",
        "model.add(Input(shape=(timesteps, input_dim)))\n",
        "model.add(SimpleRNN(50, return_sequences=False))\n",
        "\n",
        "# Add a dense output layer\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Summarize the model\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SimpleRNN Layer:**\n",
        "\n",
        "This is the recurrent layer with 50 units (neurons). It takes a sequence of shape (timesteps, input_dim) as input, where timesteps = 5 and input_dim = 10.\n",
        "The parameter `return_sequences=False` means that only the output of the last time step is passed to the next layer.\n",
        "\n",
        "**Dense Layer:**\n",
        "\n",
        "A fully connected layer with num_classes = 3 neurons, each corresponding to one output class. The `activation` function is softmax, which is typically used for multi-class classification tasks."
      ],
      "metadata": {
        "id": "V1LfEaQphBK8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample Q/A Use Case with RNN\n",
        "\n",
        "Let's build a **Question Answering problem** and solve it using `SimpleRNN`.\n",
        "\n",
        "Preparing data for **Recurrent Neural Networks(RNNs)** in TensorFlow involves several key steps to ensure that your sequential data is in the right format for training and evaluation.\n",
        "\n"
      ],
      "metadata": {
        "id": "mdUrCFUwl8n8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "emUIBm0Smhd1"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy dataset\n",
        "questions = [\n",
        "    \"What is your name?\",\n",
        "    \"How are you?\",\n",
        "    \"What is your profession?\",\n",
        "    \"Where do you live?\",\n",
        "    \"What is your favorite color?\"\n",
        "]\n",
        "\n",
        "# Corresponding answers (encoded as class labels)\n",
        "# We'll assign a unique class to each answer\n",
        "answers = [0, 1, 0, 2, 3]"
      ],
      "metadata": {
        "id": "Tnk6dHaDeDVD"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizing and Preprocessing\n",
        "* `Tokenizer`: It is used to convert words in questions into integer sequences.\n",
        "* `pad_sequences`: It ensures that all sequences are of same length by padding shorter sequences with zeros."
      ],
      "metadata": {
        "id": "199_bQLMm-kC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize tokenizer to convert text to sequences\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(questions)"
      ],
      "metadata": {
        "id": "_BqNhJApeDTE"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can check how each word is encoded using `tokenizer.word_index`"
      ],
      "metadata": {
        "id": "VUP-KRaMa8Rl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppiCt1JCa47R",
        "outputId": "5a525d4b-5c9d-44b0-9fa0-d1de62b2c30a"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'what': 1,\n",
              " 'is': 2,\n",
              " 'your': 3,\n",
              " 'you': 4,\n",
              " 'name': 5,\n",
              " 'how': 6,\n",
              " 'are': 7,\n",
              " 'profession': 8,\n",
              " 'where': 9,\n",
              " 'do': 10,\n",
              " 'live': 11,\n",
              " 'favorite': 12,\n",
              " 'color': 13}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert text to sequences of integers\n",
        "sequences = tokenizer.texts_to_sequences(questions)\n",
        "\n",
        "# Pad sequences to ensure all have the same length\n",
        "max_sequence_length = max(len(seq) for seq in sequences)\n",
        "X = pad_sequences(sequences, maxlen=max_sequence_length)"
      ],
      "metadata": {
        "id": "bw5ZcUnLmf7x"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RltoE3YWsXcr",
        "outputId": "95b81a96-fac4-43ea-e286-e992682ab7fb"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2, 3, 5], [6, 7, 4], [1, 2, 3, 8], [9, 10, 4, 11], [1, 2, 3, 12, 13]]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert answers to numpy array\n",
        "y = np.array(answers)\n",
        "\n",
        "# Print the preprocessed data\n",
        "print(\"Padded Sequences:\\n\", X)\n",
        "print(\"\\nLabels:\\n\", y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grZIWrHGmf5i",
        "outputId": "11f2bb7c-9ecb-439f-b392-587b0fce5e1a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Padded Sequences:\n",
            " [[ 0  1  2  3  5]\n",
            " [ 0  0  6  7  4]\n",
            " [ 0  1  2  3  8]\n",
            " [ 0  9 10  4 11]\n",
            " [ 1  2  3 12 13]]\n",
            "\n",
            "Labels:\n",
            " [0 1 0 2 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build and train a `SimpleRNN` model\n",
        "\n",
        "The **SimpleRNN** layer processes the input sequences. We use an embedding dimension based on the vocabulary size (number of unique words), followed by a `dense` output layer for classification.\n",
        "\n",
        "**Training:**\n",
        "The model is trained for 20 epochs using `sparse_categorical_crossentropy` as the loss function, which is suitable for multi-class classification.\n"
      ],
      "metadata": {
        "id": "JPn5Mqf-ao7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, Input"
      ],
      "metadata": {
        "id": "e0W3JvdFb4fw"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = Sequential()\n",
        "\n",
        "# Add SimpleRNN layer\n",
        "\n",
        "# 50 units in the RNN\n",
        "model.add(SimpleRNN(50, input_shape=(5, 1))) # Sending 1 feature at each time-step\n",
        "\n",
        "# Output layer (using softmax for multi-class classification)\n",
        "model.add(Dense(4, activation='softmax'))  # 4 unique answer classes\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=20, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X, y, verbose=1)\n",
        "print(f\"Model Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASJzPF4xmf3r",
        "outputId": "523a9e88-8352-46e9-8ff9-5c90c42fbd80"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.2000 - loss: 1.8836\n",
            "Epoch 2/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.2000 - loss: 1.7857\n",
            "Epoch 3/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.2000 - loss: 1.6930\n",
            "Epoch 4/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2000 - loss: 1.6053\n",
            "Epoch 5/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.2000 - loss: 1.5226\n",
            "Epoch 6/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.2000 - loss: 1.4449\n",
            "Epoch 7/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4000 - loss: 1.3724\n",
            "Epoch 8/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4000 - loss: 1.3051\n",
            "Epoch 9/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4000 - loss: 1.2434\n",
            "Epoch 10/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.4000 - loss: 1.1874\n",
            "Epoch 11/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.4000 - loss: 1.1370\n",
            "Epoch 12/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6000 - loss: 1.0922\n",
            "Epoch 13/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6000 - loss: 1.0528\n",
            "Epoch 14/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6000 - loss: 1.0182\n",
            "Epoch 15/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.9879\n",
            "Epoch 16/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.9612\n",
            "Epoch 17/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.9373\n",
            "Epoch 18/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.9155\n",
            "Epoch 19/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.8951\n",
            "Epoch 20/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8000 - loss: 0.8754\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.8000 - loss: 0.8562\n",
            "Model Accuracy: 0.8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference\n",
        "\n",
        "| Questions                       | Answers |\n",
        "|----------------------------------|---------|\n",
        "| What is your name?               | 0       |\n",
        "| How are you?                     | 1       |\n",
        "| What is your profession?         | 0       |\n",
        "| Where do you live?               | 2       |\n",
        "| What is your favorite color?     | 3       |\n",
        "\n",
        "<br>\n",
        "\n",
        "You can ask the above questions under `new_question` variable and check the output if they are true."
      ],
      "metadata": {
        "id": "jPdwPxkRhHcb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# New question for inference\n",
        "new_question = [\"How are you?\"]\n",
        "\n",
        "# Tokenize the new question (same tokenizer used during training)\n",
        "new_sequence = tokenizer.texts_to_sequences(new_question)\n",
        "\n",
        "# Pad the new sequence to the same length as the training data\n",
        "new_padded_sequence = pad_sequences(new_sequence, maxlen=max_sequence_length)\n",
        "\n",
        "# new_padded_sequence = to_categorical(new_padded_sequence, num_classes=vocab_size)\n",
        "\n",
        "# Make prediction\n",
        "predicted_probabilities = model.predict(new_padded_sequence)\n",
        "\n",
        "# Get the predicted class (answer) with the highest probability\n",
        "predicted_class = np.argmax(predicted_probabilities)\n",
        "\n",
        "# Print the predicted class\n",
        "print(f\"\\nPredicted Answer: {predicted_class}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ea5-250Dmf1l",
        "outputId": "1a9cfa11-00e7-4763-8b90-fd0ebee53f22"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step\n",
            "\n",
            "Predicted Answer: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding Layer\n",
        "\n",
        "\n",
        "\n",
        "It's primarily used to map categorical data, such as words or items, into a continuous vector space. This vector space is learned during the training process and allows the model to capture semantic relationships and similarities between the items.\n",
        "\n",
        "**Commonly used to represent words as dense vectors, capturing semantic similarities and relationships.**\n",
        "\n",
        "<img src='https://www.researchgate.net/publication/349630764/figure/fig3/AS:999014610788354@1615195052671/Detail-of-the-embedding-layer-of-the-NN-implementing-the-Encoding-model-used-for-the.png' width=400/>\n",
        "\n",
        "**Benefits:**\n",
        "* The learned embeddings often capture semantic relationships between the items. For example, words with similar meanings might be located closer together in the embedding space.\n",
        "* Using embeddings can significantly improve the performance of neural networks on tasks like text classification, machine translation, and recommendation systems.\n",
        "* Embeddings reduce the high-dimensional categorical data into a lower-dimensional, dense vector space. This makes it easier for the neural network to process and learn patterns.\n",
        "\n",
        "[`tf.keras.layers.Embedding`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding)\n"
      ],
      "metadata": {
        "id": "0wlv5IpFIF-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Sample input text\n",
        "input_text = [\"hello world\", \"this is a sentence\"]\n",
        "\n",
        "# Create a vocabulary mapping words to unique indices\n",
        "vocab = [\"hello\", \"world\", \"this\", \"is\", \"a\", \"sentence\"]\n",
        "word_to_index = {word: i for i, word in enumerate(vocab)}"
      ],
      "metadata": {
        "id": "ibWM1tr8JjBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert input text to sequences of indices\n",
        "input_sequences = [[word_to_index[word] for word in sentence.split()] for sentence in input_text]\n",
        "\n",
        "# Create an embedding layer with a vocabulary size of 6 (matching the number of words),\n",
        "# an embedding dimension of 10, and padding to ensure all sequences have the same length\n",
        "embedding_layer = tf.keras.layers.Embedding(input_dim=len(vocab), output_dim=10)\n"
      ],
      "metadata": {
        "id": "ycDe8wFvKkfO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdTFiK9UKCbM",
        "outputId": "1e2523ab-791c-44bf-e7f8-3ce287cd06de"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0 0 0 1]\n",
            " [2 3 4 5]], shape=(2, 4), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input sentences represented in a sequence of numbers."
      ],
      "metadata": {
        "id": "GcHezMqyLzH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad sequences using tf.keras.preprocessing.sequence.pad_sequences\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "input_sequences = pad_sequences(input_sequences)\n",
        "\n",
        "# Convert input_sequences to a tensor\n",
        "input_sequences = tf.convert_to_tensor(input_sequences)\n",
        "\n",
        "# Embed the input sequences\n",
        "embedded_sequences = embedding_layer(input_sequences)\n",
        "\n",
        "# Print the embedded sequences\n",
        "print(embedded_sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MS9lCTqKl3c",
        "outputId": "8b55069f-c5c0-4774-ca70-eb4f34b1a008"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0.03794252  0.00735358  0.01681856  0.01512862  0.03016\n",
            "   -0.00260349  0.03630823  0.02119816 -0.02840738  0.04478419]\n",
            "  [ 0.03794252  0.00735358  0.01681856  0.01512862  0.03016\n",
            "   -0.00260349  0.03630823  0.02119816 -0.02840738  0.04478419]\n",
            "  [ 0.03794252  0.00735358  0.01681856  0.01512862  0.03016\n",
            "   -0.00260349  0.03630823  0.02119816 -0.02840738  0.04478419]\n",
            "  [ 0.02958648  0.00542504 -0.01354098  0.00021558 -0.03900412\n",
            "   -0.03277171 -0.01506967  0.04452529 -0.02537552 -0.03426737]]\n",
            "\n",
            " [[-0.03259744  0.00101472  0.04103393  0.04218462 -0.00681552\n",
            "    0.03954779 -0.0067433  -0.0041713  -0.01401198  0.00010286]\n",
            "  [ 0.00489733  0.01479551 -0.01707581  0.04571621 -0.01512977\n",
            "   -0.01296718  0.0464029   0.03822074  0.02966138  0.03379322]\n",
            "  [ 0.0107684   0.00302047 -0.03436047  0.04098428 -0.03694846\n",
            "    0.03046945 -0.03059861 -0.03292129  0.03471323  0.04706914]\n",
            "  [-0.03682158 -0.00249442  0.02136289  0.03434719  0.02933452\n",
            "    0.001809    0.01189711 -0.02096309  0.01152878 -0.02240356]]], shape=(2, 4, 10), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now both the sentences are represented as a sequence of vectors."
      ],
      "metadata": {
        "id": "8Ky3NlVEL6zq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis using RNN"
      ],
      "metadata": {
        "id": "3acd-Fq00wdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load the IMDB dataset\n",
        "data = tf.keras.datasets.imdb.load_data()\n",
        "(x_train, y_train), (x_test, y_test) = data"
      ],
      "metadata": {
        "id": "ucnFs8RH9vWA"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the reviews in this dataset have already been tokenized. <br>\n",
        "If we check the first review in the training set,"
      ],
      "metadata": {
        "id": "M6NdQjlN9RWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"First review in the training set:\\n\", x_train[0], \"length:\", len(x_train[0]), \"class:\", y_train[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvWpurtc6OGT",
        "outputId": "5daff4f1-36ef-4853-fadc-d56df4695c48"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First review in the training set:\n",
            " [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32] length: 218 class: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 10000  # Limit the vocabulary size to the top 10,000 words\n",
        "maxlen = 200  # Limit each review to 200 words\n",
        "\n",
        "# Pad sequences to have the same length\n",
        "x_train = pad_sequences(x_train,padding='post',maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test,padding='post',maxlen=maxlen)\n"
      ],
      "metadata": {
        "id": "WmSdWmTS9zQD"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The max length of sequence is quite huge. Hence, we try to limit it to a max length of 100 to avoid inconsistencies while training."
      ],
      "metadata": {
        "id": "j2LVFNRe-Gmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DP7CB-VYAQky",
        "outputId": "3dd0fc4c-c855-4e63-b2f7-f1f6457bae74"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create an RNN model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, 32),\n",
        "    tf.keras.layers.SimpleRNN(64),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "z4XhrbFr0HXn",
        "outputId": "648726b3-ebce-4515-9968-c6e5f8e79de3"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_11 (\u001b[38;5;33mEmbedding\u001b[0m)             │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn_12 (\u001b[38;5;33mSimpleRNN\u001b[0m)            │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)            │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=64, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZmtvtMcACIs",
        "outputId": "9cba4252-c2d1-47bd-eddc-8f8c84548f1d"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 30ms/step - accuracy: 0.7512 - loss: 0.3989 - val_accuracy: 0.5126 - val_loss: 0.8896\n",
            "Epoch 2/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.7368 - loss: 0.4006 - val_accuracy: 0.5162 - val_loss: 1.0451\n",
            "Epoch 3/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.7592 - loss: 0.3639 - val_accuracy: 0.5268 - val_loss: 1.0858\n",
            "Epoch 4/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - accuracy: 0.7768 - loss: 0.3427 - val_accuracy: 0.5150 - val_loss: 1.1806\n",
            "Epoch 5/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.7804 - loss: 0.3477 - val_accuracy: 0.5102 - val_loss: 1.1360\n",
            "Epoch 6/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.7886 - loss: 0.3363 - val_accuracy: 0.5126 - val_loss: 1.2723\n",
            "Epoch 7/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.7995 - loss: 0.3282 - val_accuracy: 0.5128 - val_loss: 1.1977\n",
            "Epoch 8/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - accuracy: 0.7942 - loss: 0.3306 - val_accuracy: 0.5114 - val_loss: 1.2165\n",
            "Epoch 9/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.7946 - loss: 0.3364 - val_accuracy: 0.5292 - val_loss: 1.3223\n",
            "Epoch 10/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.8058 - loss: 0.3144 - val_accuracy: 0.5046 - val_loss: 1.2895\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c3090e584c0>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fT1f2_3e3tQc",
        "outputId": "9ef2ba49-24dc-49ac-a98d-020410893b6f"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.5159 - loss: 1.2598\n",
            "Test Accuracy: 0.5174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have the model and tokenizer defined as in the previous code\n",
        "\n",
        "tokenizer = Tokenizer(num_words=100)\n",
        "\n",
        "# Convert a new text to a sequence\n",
        "new_text = \"the movie was bad!\"\n",
        "tokenizer.fit_on_texts(new_text)\n",
        "new_sequence = tokenizer.texts_to_sequences([new_text])\n",
        "new_sequence = pad_sequences(new_sequence, maxlen=100)\n",
        "\n",
        "# Make a prediction\n",
        "prediction = model.predict(new_sequence)\n",
        "\n",
        "print(prediction)\n",
        "# Interpret the prediction (assuming a binary classification task)\n",
        "if prediction[0][0] > 0.5:\n",
        "    print(\"Positive sentiment\")\n",
        "else:\n",
        "    print(\"Negative sentiment\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVsBURxY0HTW",
        "outputId": "4dfeecfe-992e-4668-e358-025fbd800546"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "[[0.44447953]]\n",
            "Negative sentiment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improvement Strategies\n",
        "\n",
        "Consider the following strategies to help improve the accuracy of the above model.\n",
        "\n",
        "1. **Increase max length of sequence:** Increasing the maxlen might help in increasing the accuracy as more information from each review would be available to the model.\n",
        "2. **Increase the number of epochs**: The model might need more training iterations to learn the patterns in the data effectively.\n",
        "3. **Add more RNN layers:** Stacking multiple RNN layers can help the model capture more complex dependencies in the sequence.\n",
        "  * **Increase the number of units in the RNN layers:** More units can enhance the model's capacity to learn intricate patterns.\n",
        "4. **Adjust the learning rate:** Fine-tuning the learning rate can impact the model's convergence speed and performance.\n"
      ],
      "metadata": {
        "id": "oCcp6RxcGsy0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "25CivCq5eDP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dKqYKqxj58xI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v3KEC5ux58vA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XLVpbxdG58su"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DD4e1LHC58pN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W9CoJ3eV58nM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fFFPMmOw58kz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}