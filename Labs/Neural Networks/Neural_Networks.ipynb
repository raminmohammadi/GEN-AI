{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEjJ7raoDTu_"
      },
      "source": [
        "# Perceptron\n",
        "\n",
        "A **Perceptron** is a simple artificial neural network unit that takes multiple inputs, performs a weighted sum of these inputs, and applies a threshold function to produce an output.\n",
        "\n",
        "It's essentially a basic building block of neural networks, serving as a simplified model of a biological neuron.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=18Ar9x38STGTjuRCzJe90Oha6cDmFhE3J\" width=\"400\">\n",
        "\n",
        "**Inputs**: A neuron takes multiple inputs, often represented as x\n",
        "1\n",
        "​\n",
        " ,x\n",
        "2\n",
        "​\n",
        " ,…,x\n",
        "n\n",
        "​\n",
        " , each of which is associated with a weight w\n",
        "1\n",
        "​\n",
        " ,w\n",
        "2\n",
        "​\n",
        " ,…,w\n",
        "n\n",
        "​\n",
        " . A bias term b is usually added as well.\n",
        "\n",
        "**Weighted Sum**: The neuron calculates a weighted sum of the inputs z, using the formula:\n",
        "\n",
        "$$\n",
        "z = \\sum_{i=1}^{n} w_i x_i + b\n",
        "$$\n",
        "\n",
        "**Activation Function**: The neuron then applies an activation function to this weighted sum to introduce non-linearity into the model.\n",
        "$$\n",
        "a = f(z)\n",
        "$$\n",
        "\n",
        "Common activation functions include the sigmoid, ReLU, and tanh functions.\n",
        "\n",
        "**Output**: The result, α  is the neuron's output, which is passed to the next layer in the network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDLZzhffGmvM"
      },
      "source": [
        "## Perceptron implementation on `XOR` data using TensorFlow\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jz0OO-7UMAAA"
      },
      "outputs": [],
      "source": [
        "# Importing the libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N77yJSbquDAm"
      },
      "source": [
        "Create sample input features (X) and corresponding labels (y) for a simple XOR problem.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1dkHgBdM2QBpL2IHdJtbN3fFLvkL8E84M\" width=400/>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vTpe6TZMcQm"
      },
      "outputs": [],
      "source": [
        "# Defining the dataset\n",
        "\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])  # Input features\n",
        "y = np.array([0, 1, 1, 0])  # Corresponding labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNCD2uP5uNMX"
      },
      "source": [
        " Define a perceptron model with a single neuron using `tf.keras.Sequential`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AcQnhUDPDVpe"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(2,)),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eY5Ry0Cgt18I"
      },
      "source": [
        "**Important Arguments:**\n",
        "\n",
        "* `Dense` layer represents the perceptron\n",
        "* `sigmoid` activation function is used to produce output values between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzUxOG_wqVkG"
      },
      "outputs": [],
      "source": [
        "# Compiling the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz9zi1hrqNS0"
      },
      "source": [
        "**Important Arguments:**\n",
        "\n",
        "* `Adam optimizer` is used to update weights during training. It maintains moving averages of the first and second moments of gradients.\n",
        "* `Binary_crossentropy` cost function is used to measure the model's error. It calculates the difference between the predicted probabilities and the true binary labels.  It penalizes incorrect predictions more heavily.\n",
        "* `accuracy` is used to validate the performace of the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "omi5BJyEL3mQ",
        "outputId": "2cc84b92-e0ad-48a9-f056-c464f0300dcf"
      },
      "outputs": [],
      "source": [
        "# Fitting the model\n",
        "history = model.fit(X, y, epochs=100, batch_size=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSLukpCEtP48"
      },
      "source": [
        "**Important Arguments:**\n",
        "\n",
        "* `X, y`: Training data and labels.\n",
        "* `batch_size`: Number of samples per gradient update.\n",
        "* `epochs`: Number of epochs to train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrHH1kjCMy9x",
        "outputId": "6a47bfb5-3a4b-4fec-c6c5-61838f9c7032"
      },
      "outputs": [],
      "source": [
        "# Evaluating the model\n",
        "loss, accuracy = model.evaluate(X, y)\n",
        "print(\"Loss:\", loss)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "MkEqGmABgM4Y",
        "outputId": "f037bd49-4730-4b40-8183-c5915df43459"
      },
      "outputs": [],
      "source": [
        "# Set a threshold for loss and accuracy\n",
        "loss_threshold = 0.1\n",
        "accuracy_threshold = 0.9\n",
        "\n",
        "# Create a bar chart to visualize the values against thresholds\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.bar(['Validation Loss', 'Validation Accuracy'], [loss, accuracy])\n",
        "plt.axhline(y=loss_threshold, color='r', linestyle='-', label='Loss Threshold')\n",
        "plt.axhline(y=accuracy_threshold, color='g', linestyle='-', label='Accuracy Threshold')\n",
        "plt.title('Model Evaluation')\n",
        "plt.ylabel('Value')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mq0rtEc7q5EH"
      },
      "source": [
        "Here we can clearly see the **perceptron's** inability to learn the **XOR** function. A single-layer perceptron is incapable of learning this function because it can only represent linearly separable data. The **XOR problem, however, is not linearly separable**. This means it's impossible to draw a straight line to separate the data points into two classes. <br> <br>\n",
        "\n",
        "To address this issue, lets build a neural network that can introduce **nonlinearity** and allow it to learn more complex patterns, including the XOR function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuTEkmbZN7v9"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5JkMTe_N98k"
      },
      "source": [
        "# Neural Networks\n",
        "\n",
        "A **neural network** is created by connecting several nodes so that the output of some nodes serves as the input\n",
        "to others.\n",
        "In a neural network, the layers of nodes are organized into three main types: the input layer, the hidden\n",
        "layer, and the output layer. The input layer consists of nodes that represent the input features of the data,\n",
        "and it also includes special bias units that always output a value of +1. <br><br> The hidden layer is where the\n",
        "network processes the information through weights and biases to learn patterns. This layer’s nodes are not\n",
        "directly observed in the data but play a crucial role in transforming the inputs into meaningful outputs.\n",
        "Finally, the output layer provides the final prediction or result of the network. In our example, there are 3\n",
        "input nodes, 3 hidden nodes, and 1 output node.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1ZNF4e_DWy3hZhZRKKB7orJPudD8kOx4t\" width=400>\n",
        "\n",
        "**Basic Architecture:**\n",
        "* **Input Layer:** The first layer receives the input data, which can be images, text, numerical data, or any other suitable format.\n",
        "* **Hidden Layers:** These layers process the input data and extract relevant features. They can be multiple layers, each with a different number of neurons.\n",
        "* **Output Layer:** The final layer produces the output, which can be a classification, regression, or other desired result.\n",
        "\n",
        "**Key Components:**\n",
        "* **Neurons:** The fundamental units of a neural network, each representing a simple computational unit.\n",
        "* **Weights:** Numerical values that determine the strength of connections between neurons.\n",
        "* **Biases:** Additional parameters that adjust the output of a neuron.\n",
        "Activation Functions: Non-linear functions that introduce complexity and enable the network to learn complex patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZS1S2nlyJ_5y"
      },
      "source": [
        "## Neural Networks implementation on `XOR` data using TensorFlow\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TGXMWpzFag3F",
        "outputId": "7d7ca678-a6ed-4fab-fb18-b7f58a0dd658"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(3, activation='relu', input_shape=(2, )), # 1 hidden layer with 3 neurons\n",
        "    tf.keras.layers.Dense(3, activation='relu'), # 1 hidden layer with 3 neurons\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid'), # Output layer with 1 neuron\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "vlJsRFJInOi9",
        "outputId": "c084e3e0-445f-4b42-98a7-14f78210c6b3"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98iCWIr3ag5X"
      },
      "outputs": [],
      "source": [
        "# Compiling the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UGY5IXdsag7m",
        "outputId": "31b0504c-197d-4b9a-a6ad-ba4afc1f4a51"
      },
      "outputs": [],
      "source": [
        "# Fitting the model\n",
        "history = model.fit(X, y, epochs=100, batch_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tG9wlC4PapfJ",
        "outputId": "5040e58d-0af0-402d-9ce0-10cbebf1f334"
      },
      "outputs": [],
      "source": [
        "# Evaluating the model\n",
        "loss, accuracy = model.evaluate(X, y)\n",
        "print(\"Loss:\", loss)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "2_1QD4YhlRie",
        "outputId": "687dcded-d3d7-4544-a693-ddeaa2825aff"
      },
      "outputs": [],
      "source": [
        "# Set a threshold for loss and accuracy\n",
        "loss_threshold = 0.1\n",
        "accuracy_threshold = 0.9\n",
        "\n",
        "# Create a bar chart to visualize the values against thresholds\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.bar(['Validation Loss', 'Validation Accuracy'], [loss, accuracy])\n",
        "plt.axhline(y=loss_threshold, color='r', linestyle='-', label='Loss Threshold')\n",
        "plt.axhline(y=accuracy_threshold, color='g', linestyle='-', label='Accuracy Threshold')\n",
        "plt.title('Model Evaluation')\n",
        "plt.ylabel('Value')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHUyInc7dAA3"
      },
      "source": [
        "As we can see here, **Neural networks** achieved significantly higher accuracy than a **perceptron**. It is because of their ability to learn complex patterns, represent **non-linear** relationships and benefit from **backpropagation** and automatic feature learning make them a powerful tool for a wide range of machine learning tasks.\n",
        "<br>\n",
        "\n",
        "While perceptrons are a simpler model, they are often limited in their ability to handle complex problems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmQZJUlule_A"
      },
      "source": [
        "# Neural Networks implementation on `MNIST` data using TensorFlow\n",
        "\n",
        "## MNIST Dataset\n",
        "\n",
        "The MNIST (Modified National Institute of Standards and Technology) database is a widely used dataset in the field of machine learning,\n",
        "specifically for image classification tasks. It consists of 60,000 training images and 10,000 testing images, each 28x28 grayscale images of **handwritten digits** from 0 to 9. ([learn more](https://colah.github.io/posts/2014-10-Visualizing-MNIST/))\n",
        "\n",
        "<img src='https://miro.medium.com/v2/resize:fit:1280/format:webp/1*B9pCFLFsx50PGaCYy2U_sw.gif' width=300>\n",
        "\n",
        "## Problem\n",
        "Now the idea is to input each handwritten digit to the neural network and classify what that image of the hand written digit signifies.\n",
        "\n",
        "<img src='https://miro.medium.com/v2/resize:fit:1160/format:webp/0*u5-PcKYVfUE5s2by.gif' width=400>\n",
        "\n",
        "As the above image suggests,\n",
        "* Each image of the handwritten digit is **flattened** first. That is,\n",
        "  * **Image shape:** (28, 28, 1)\n",
        "  * **After Flattening:** (784, 1)\n",
        "  * We are simply multiplying the first 2 dimensions of the image.\n",
        "* Now this flattened image is passed down to the feed forward neural network through the hidden layers and finally outputs the result between 0 to 9.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fytw8oaADMr8"
      },
      "source": [
        "## Load and preprocess the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfY5qZ8NCUZp"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEja82t9CaJa",
        "outputId": "702c0206-f76d-49d4-8884-1f4eb1508256"
      },
      "outputs": [],
      "source": [
        "# 1. Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTxdOFg7uZ1i"
      },
      "source": [
        "### Normalization\n",
        "\n",
        "The pixel values are **normalized** to the range\n",
        "[0,1] by dividing by 255.\n",
        "\n",
        "* **Without normalization**, the network would see input features (pixel values) that vary significantly in scale (some very high, others low).\n",
        "* When features have large values, they can cause larger weight updates during backpropagation, leading to a very erratic optimization process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25RTufA4Ce_r"
      },
      "outputs": [],
      "source": [
        "# Normalize the pixel values to be between 0 and 1\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9W_01TLChzt"
      },
      "outputs": [],
      "source": [
        "# Flatten the images to 1D vectors (28*28 = 784 features)\n",
        "x_train = x_train.reshape(-1, 28 * 28)\n",
        "x_test = x_test.reshape(-1, 28 * 28)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66rpQepjqmUH"
      },
      "source": [
        "### Converting labels to one hot vector?\n",
        "\n",
        "The digits 0,1,2,…,9 are categorical (i.e., different classes), not ordinal. If you use the raw label numbers (e.g., 0, 1, 2, etc.) directly, the model may assume there's a numerical relationship between them, like 9 is greater than 0 or 2 is less than 3. This is not true in classification tasks.\n",
        "\n",
        "One-hot encoding prevents the model from assigning importance or relationships based on the magnitude of the class labels, by creating an independent binary vector for each class.\n",
        "\n",
        "**One hot encoding representation:**\n",
        "\n",
        "<img src='https://codecraft.tv/courses/tensorflowjs/neural-networks/mnist-training-data/img/exports/5.mnist.001.jpeg' width=500>\n",
        "\n",
        "Here:\n",
        "\n",
        "* The length of the vector is equal to the number of classes (10 in the case of MNIST).\n",
        "* The value 1 is placed in the position corresponding to the true class (9 in this case), and all other positions are 0.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwmfArZ3Ck6t"
      },
      "outputs": [],
      "source": [
        "# Convert labels to one-hot encoding\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1Pk2L7pCoKI"
      },
      "source": [
        "## Building the model\n",
        "\n",
        "We shall be building a neural network using `tf.keras.Sequential`.\n",
        "* **Input:** 784 flattened features of the image\n",
        "* **Hidden layer 1:** 128 neurons\n",
        "* **Hidden layer 2:** 64 neurons\n",
        "* **Output:** 10 neurons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNadah0mCK_1"
      },
      "outputs": [],
      "source": [
        "# 2. Build the feedforward neural network model\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(28 * 28,)),  # Input layer (28x28 = 784 flattened image)\n",
        "    layers.Dense(128, activation='relu'),  # Fully connected layer with 128 neurons\n",
        "    layers.Dense(64, activation='relu'),  # Another fully connected layer with 64 neurons\n",
        "    layers.Dense(10, activation='softmax')  # Output layer with 10 neurons for 10 classes\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "1laiDEwG0u5z",
        "outputId": "11eb15e5-694c-4cc5-e141-e76d7c50a1f7"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRMq7BNsC8U_"
      },
      "source": [
        "## Compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z84GScNoCMnB"
      },
      "outputs": [],
      "source": [
        "# 3. Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPxBl8vYDAKt"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkPYiPTQCMpQ",
        "outputId": "1bb076fd-a899-4823-cacf-df30fd4bb924"
      },
      "outputs": [],
      "source": [
        "# 4. Train the model\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=64, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKdJq0sZDFap"
      },
      "source": [
        "## Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZWVJpbpCMra",
        "outputId": "da9dba8d-9bfe-415c-8a83-577ce8ee0b65"
      },
      "outputs": [],
      "source": [
        "# 5. Evaluate the model\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "IRt3Y4zqCMtb",
        "outputId": "7c3ec635-f899-4a38-9893-e4397b127be8"
      },
      "outputs": [],
      "source": [
        "# Plotting training & validation accuracy values\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='upper left')\n",
        "\n",
        "# Plotting training & validation loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBKGRPqqCMyd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnXgwJKvCNXp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "miLcBE_pVZsK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
