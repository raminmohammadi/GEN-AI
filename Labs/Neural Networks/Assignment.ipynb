{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Networks Assignment (Graded)\n",
        "\n",
        "Welcome to your first (required) programming assignment! You will build a Neural Network to recognize various everyday objects. This assignment will step you through how to do this with a Neural Network mindset, and will also hone your intuitions about deep learning.\n",
        "\n",
        "**Instructions:**\n",
        "* Do not modify any of the codes.\n",
        "* Only write code when prompted. For example in some sections you will find the following,\n",
        "```\n",
        "# YOUR CODE GOES HERE\n",
        "# YOUR CODE ENDS HERE\n",
        "# TODO\n",
        "```\n",
        "Only modify those sections of the code.\n",
        "\n",
        "**You will learn to:**\n",
        "* Explore the CIFAR10 dataset: https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "* Build the general architecture of a neural network, including:\n",
        "  * Initializing parameters\n",
        "  * Calculating the cost function and its gradient\n",
        "  * Using an optimization algorithm (gradient descent)\n",
        "* Gather all three functions above into a main model function, in the right order."
      ],
      "metadata": {
        "id": "Yxr4Ouv5iAWI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ExlUsmmEeBr"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from helpers import *\n",
        "from tests import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import dataset\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "# Load dataset into training and testing sets\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ANm-IEvMk6sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing the dataset"
      ],
      "metadata": {
        "id": "mPvrUtY1lc7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualize a grid of images from the training set\n",
        "display_image_grid(X_train[:32], y_train[:32])\n"
      ],
      "metadata": {
        "id": "c3NLWsKzlJe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### How many images does the training dataset contain?\n"
      ],
      "metadata": {
        "id": "VEbDPxFymHBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE GOES HERE\n"
      ],
      "metadata": {
        "id": "TSL1kZX9lV_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Expected Output:**\n",
        "```\n",
        "50000\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "tq5Bs5C8l77p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### How many images does the testing dataset contain?\n"
      ],
      "metadata": {
        "id": "m2lPHZ6MmaLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE GOES HERE\n"
      ],
      "metadata": {
        "id": "cP3L3wWMlV80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Expected Output:**\n",
        "```\n",
        "10000\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "LwvJbFr3me2-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### How many output classes does the dataset contain? Can you list them?"
      ],
      "metadata": {
        "id": "UebRvBrZmnDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE GOES HERE\n"
      ],
      "metadata": {
        "id": "rbSnoO9QmhQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expected Output:**\n",
        "```\n",
        "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)\n",
        "```"
      ],
      "metadata": {
        "id": "73RVL_oQm3aB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Find out the total number of images in each class."
      ],
      "metadata": {
        "id": "Ezu2FORBoP3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n",
        "\n",
        "num_classes = len(np.unique(y_train))\n",
        "for cls in range(num_classes):\n",
        "  count = 0\n",
        "  # YOUR CODE GOES HERE\n",
        "\n",
        "  # YOUR CODE ENDS HERE\n",
        "  print(\"Number of images belonging to {} is {}\".format(cls, count))"
      ],
      "metadata": {
        "id": "v1OzkFmqmhKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expected Output:**\n",
        "```\n",
        "Number of images belonging to 0 is 5000\n",
        "Number of images belonging to 1 is 5000\n",
        "Number of images belonging to 2 is 5000\n",
        "Number of images belonging to 3 is 5000\n",
        "Number of images belonging to 4 is 5000\n",
        "Number of images belonging to 5 is 5000\n",
        "Number of images belonging to 6 is 5000\n",
        "Number of images belonging to 7 is 5000\n",
        "Number of images belonging to 8 is 5000\n",
        "Number of images belonging to 9 is 5000\n",
        "```"
      ],
      "metadata": {
        "id": "8mSgHNaMoiwd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "BRf4ITfutgAV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing the dataset\n",
        "We shall be performing the following steps to preprocess our dataset in order to get the highest possible model performance:\n",
        "\n",
        "1. **Normalization:** Scaling down the pixel values between 0 to 1.\n",
        "2. **Flattening:** Flattenning the dataset such that the shape of the image (num_px, num_px, 3) are flattened into single vectors of shape (num_px\n",
        " num_px\n",
        " 3, 1).\n",
        "3. **One Hot Encoding:** Encoding the values into a one hot vector."
      ],
      "metadata": {
        "id": "ASCy6xBlqL5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n",
        "\n",
        "def data_preprocessing(X_train, X_test, y_train, y_test):\n",
        "\n",
        "  \"\"\"Preprocesses the training and testing data for a machine learning model.\n",
        "\n",
        "  Args:\n",
        "      X_train: Training dataset features.\n",
        "      X_test: Testing dataset features.\n",
        "      y_train: Training dataset labels.\n",
        "      y_test: Testing dataset labels.\n",
        "\n",
        "  Returns:\n",
        "      X_train: Preprocessed training dataset features.\n",
        "      X_test: Preprocessed testing dataset features.\n",
        "      y_train: Preprocessed training dataset labels.\n",
        "      y_test: Preprocessed testing dataset labels.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Data Normalization\n",
        "  # YOUR CODE GOES HERE\n",
        "  X_train =\n",
        "  X_test =\n",
        "\n",
        "  # Flattening\n",
        "  # YOUR CODE GOES HERE\n",
        "  X_train =\n",
        "  X_test =\n",
        "\n",
        "  # One Hot Encoding\n",
        "  # YOUR CODE GOES HERE\n",
        "  y_train_oh =\n",
        "  y_test_oh =\n",
        "\n",
        "  # YOUR CODE ENDS HERE\n",
        "  preprocessing_tests(X_train, X_test, y_train_oh, y_test_oh)\n",
        "\n",
        "  return X_train, X_test, y_train_oh, y_test_oh\n",
        "\n"
      ],
      "metadata": {
        "id": "hdWbFnGv0KAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Building\n",
        "\n",
        "Here, you shall be building a feedforward neural network with atleast 3 hidden neurons."
      ],
      "metadata": {
        "id": "4uqKyr8fxJLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n",
        "\n",
        "# Import necessary modules\n",
        "\n",
        "\n",
        "def build_model(input_shape, num_classes):\n",
        "    \"\"\"Builds a feedforward neural network model.\n",
        "\n",
        "    Args:\n",
        "        input_shape: Tuple specifying the input shape.\n",
        "        num_classes: Number of output classes.\n",
        "\n",
        "    Returns:\n",
        "        Compiled Keras model.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(Input(input_shape))\n",
        "\n",
        "    # Add at least 3 hidden layers with 'relu' activation function\n",
        "    # Also ensure that the final layer has 10 neurons\n",
        "\n",
        "    # YOUR CODE GOES HERE\n",
        "\n",
        "\n",
        "    # YOUR CODE ENDS HERE\n",
        "    test_model_structure(model)\n",
        "    return model"
      ],
      "metadata": {
        "id": "Ry2jsVw-qSZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training and Evaluation\n",
        "\n"
      ],
      "metadata": {
        "id": "HE8G5fjM-Uc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(43)  # for reproducibility\n",
        "tf.random.set_seed(43)  # for reproducibility"
      ],
      "metadata": {
        "id": "52rShwNBv4RS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def compile_model(model):\n",
        "  \"\"\"Compiles the given model.\n",
        "\n",
        "  Args:\n",
        "      model(tf.keras.Model): The model to be compiled.\n",
        "\n",
        "  Returns:\n",
        "      None\n",
        "  \"\"\"\n",
        "  #Compile the model such that add a categorical cross entropy loss function,\n",
        "  # adam optimizer and measure the performance using 'Accuracy' metric.\n",
        "\n",
        "  # YOUR CODE GOES HERE\n",
        "\n",
        "  # YOUR CODE ENDS HERE\n",
        "  test_model_compilation(model)\n"
      ],
      "metadata": {
        "id": "onglEWs0IS0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(x_train, y_train, model, epochs, val_split, batch_sz):\n",
        "    \"\"\"Trains the model using the provided training data.\n",
        "\n",
        "    Args:\n",
        "        x_train: Training dataset features.\n",
        "        y_train: Training dataset labels.\n",
        "        model (tf.keras.Model): The compiled neural network model.\n",
        "        epochs (int, optional): Number of epochs to train the model. Defaults to 10.\n",
        "        val_split (float, optional): Fraction of the training data to be used as validation data. Defaults to 0.2.\n",
        "\n",
        "    Returns:\n",
        "        tf.keras.callbacks.History: The training history object.\n",
        "    \"\"\"\n",
        "    device = detect_and_set_device()\n",
        "    with tf.device('/' + device + ':0'):\n",
        "\n",
        "        history = model.fit(\n",
        "            x_train, y_train,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_sz,\n",
        "            validation_split=val_split,\n",
        "        )\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "UY6UUUWFISx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and evaluation\n",
        "\n",
        "Here, you shall be building a pipeline from preprocessing the dataset to training on it.<br>\n",
        "Complete all the TODOs in the following section.\n",
        "<br>\n",
        "Also, you need to **achieve atleast 50% on the validation accuracy to pass this test.**"
      ],
      "metadata": {
        "id": "Da2mbINsrauh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # TODO\n",
        "\n",
        "def main(epochs, val_split, batch_sz):\n",
        "  \"\"\"Main function to run the training pipeline.\n",
        "\n",
        "    Args:\n",
        "        epochs(int, optional): Number of epochs to train the model.\n",
        "        val_split: Fraction of the training data to be used as validation data.\n",
        "        batch_sz: Batch size for training.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "\n",
        "  \"\"\"\n",
        "  # (TODO)Preprocess the data\n",
        "  x_train, x_test, y_train_oh, y_test_oh =\n",
        "\n",
        "  # (TODO)Build Model\n",
        "  model =\n",
        "\n",
        "  # (TODO)Compile model\n",
        "\n",
        "  # Train model\n",
        "  history = train_model(x_train, y_train_oh, model, epochs=epochs, val_split=val_split, batch_sz=batch_sz)\n",
        "\n",
        "  test_loss, test_acc = model.evaluate(x_test, y_test_oh)\n",
        "  print('Test accuracy:', test_acc)\n",
        "\n",
        "  y_pred = model.predict(x_test)\n",
        "  y_pred = np.argmax(y_pred, axis=1)\n",
        "  y_true = np.argmax(y_test_oh, axis=1)\n",
        "\n",
        "  # Plots\n",
        "  plot_metrics(history)\n",
        "  plot_predictions(X_test, y_true, y_pred, num_samples=16)\n",
        "  plot_label_comparison(y_true, y_pred)\n",
        "\n",
        "  test_model_accuracy(history=history)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # (TODO) Feel free to adjust the parameters\n",
        "    main(epochs=10, val_split=0.2, batch_sz=32)"
      ],
      "metadata": {
        "id": "htkVwATt9aIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improvement Strategies\n",
        "\n",
        "Consider the following strategies to help improve the accuracy of the above model.\n",
        "\n",
        "\n",
        "1. **Increase the number of epochs**: The model might need more training iterations to learn the patterns in the data effectively.\n",
        "2. **Add more FFN layers:** Stacking multiple FFN layers can help the model capture more complex dependencies.\n",
        "3. **Adjust the learning rate:** Fine-tuning the learning rate can impact the model's convergence speed and performance.\n",
        "4. **Try different Optimizers:** Explore various optimization algorithms (e.g., SGD, RMSprop).\n",
        "Replace Adam in the `compile_model` function with another optimizer from `keras.optimizers`.\n"
      ],
      "metadata": {
        "id": "TYESpO4uQeea"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SNzVur9tBQno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FzKObtQKBQlB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}