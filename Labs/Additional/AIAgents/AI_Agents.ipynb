{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmBjCXkkacq5"
   },
   "source": [
    "# Building Intelligent Agents with LangChain: A Practical Guide\n",
    "\n",
    "LangChain has revolutionized the way we build AI applications by providing a robust framework for creating specialized agents that can perform complex tasks autonomously. This notebook demonstrates the practical implementation of five distinct agents, each designed to showcase different capabilities of the LangChain framework.\n",
    "\n",
    "## Overview of Agents\n",
    "\n",
    "**Basic Prompt-Tuned Agent**\n",
    "We begin with a fundamental agent that demonstrates how system prompt engineering can significantly enhance an agent's performance. This serves as an excellent introduction to agent architecture and behavior customization.\n",
    "\n",
    "**Search-Enhanced Agent**\n",
    "Building upon the basics, we implement a search-capable agent using TavilySearch integration. This agent showcases how to effectively combine language models with real-time web search capabilities to provide up-to-date and accurate information.\n",
    "\n",
    "**SQL Database Agent**\n",
    "The SQL Database Agent illustrates the power of combining natural language processing with database operations. This agent can interpret natural language queries and convert them into SQL commands, making database interactions more accessible to non-technical users.\n",
    "\n",
    "**Arxiv Paper Summarizer**\n",
    "This specialized agent demonstrates how to create task-specific agents by integrating with the Arxiv API. It can fetch, process, and summarize academic papers, making research more accessible and digestible.\n",
    "\n",
    "**Custom Plot Agent**\n",
    "The final agent showcases data visualization capabilities by creating custom plots based on natural language descriptions. This implementation highlights how to combine language models with visualization libraries for intuitive data representation.\n",
    "\n",
    "Through these implementations, we explore key concepts in agent development, including:\n",
    "- Tool integration and customization\n",
    "- Prompt engineering and system message design\n",
    "- API interactions and data processing\n",
    "- Visualization and output formatting\n",
    "\n",
    "This notebook serves as both a practical guide and a reference for building specialized AI agents using LangChain, suitable for developers looking to create their own custom AI solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94AuAYGxIe5y"
   },
   "source": [
    "## Setup APIs\n",
    "\n",
    "Before you get started, make sure you keep the API keys ready for the following tools:\n",
    "\n",
    "1. [groq cloud](https://console.groq.com)\n",
    "2. [Tavily Search](https://tavily.com)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PHis5m4d3vOi"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "TAVILY_API_KEY='YOUR_API_KEY'\n",
    "GROQ_API_KEY='YOUR_API_KEY'\n",
    "\n",
    "os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY\n",
    "os.environ['GROQ_API_KEY'] = GROQ_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lu4lMA0FGbFJ"
   },
   "source": [
    "## Setting up the llm\n",
    "\n",
    "We'll be using the most powerful `llama3-70b` model hosted by groq for free."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QFiKJd9-IiKX"
   },
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Make sure you setup your ChatGroq api key first\n",
    "llm = ChatGroq(model_name=\"llama3-70b-8192\")\n",
    "response = llm.invoke('Hey, tell me a joke!')\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axOPBmoBKa5_"
   },
   "source": [
    "## Prompt-Tuned Agent\n",
    "\n",
    "* We will build an agent that can only answer questions about crypto.\n",
    "\n",
    "* For this, we are only going to tune the system prompt of our llm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vh7VZr3LKf2Y"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Defining our prompt template\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You only answer to crypto-related questions, and for all other questions: you say 'I cannot help you with that!'\"),\n",
    "    (\"placeholder\", \"{messages}\"),\n",
    "    (\"user\", \"Remember, always be polite!\") ])\n",
    "\n",
    "# Creating an agent chain using pipe '|'\n",
    "agent = prompt | llm\n",
    "\n",
    "response = agent.invoke({\"messages\": ['Hey, tell me a joke']})\n",
    "\n",
    "# Remember that our agent will only answer questions relating to crypto.\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5mtzoMvHLCo8"
   },
   "outputs": [],
   "source": [
    "# Lets ask something that's related to crypto\n",
    "response = agent.invoke({\"messages\": [HumanMessage(content='Hey, what is btc?')]})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uf_FZTdpKA44"
   },
   "source": [
    "## Search-Enhanced Agent\n",
    "\n",
    "Lets integrate `TavilySearchTool` which will be helpful for our agent to provide responses using the internet.\n",
    "\n",
    "For this purpose, we are going to turn to `create_react_agent` to build our agent.\n",
    "\n",
    "Make sure you keep the free [TavilySearch](https://tavily.com/) API key ready.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iu20CeISKULb"
   },
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# Ready the search tool\n",
    "search = TavilySearchResults(max_results=2)\n",
    "tools = [search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M0JUeaoQPHYP"
   },
   "outputs": [],
   "source": [
    "# Lets slightly modify our system prompt to ask the llm to prompt the user with follow up questions\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You only answer to crypto-related questions, and for all other questions: you say 'I cannot help you with that!'. Also prompt the user with example follow up questions.\"),\n",
    "    (\"placeholder\", \"{messages}\"),\n",
    "    (\"user\", \"Remember, always be polite!\") ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1wV6tE8wMg4j"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Here we initilialize our llm along with tools and prompt template\n",
    "agent_executor = create_react_agent(llm, tools, prompt=prompt)\n",
    "\n",
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content='what is btc?!')]}\n",
    "):\n",
    "    if 'agent' in chunk:\n",
    "      print(chunk['agent']['messages'][0].content)\n",
    "      print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLW2nyBzN0QD"
   },
   "outputs": [],
   "source": [
    "# Asking a follow up question (which our agent fails to answer accurately)\n",
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content='Yes, am interested to know how it works')]}\n",
    "):\n",
    "    if 'agent' in chunk:\n",
    "      print(chunk['agent']['messages'][0].content)\n",
    "      print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvdvBJtONjxJ"
   },
   "source": [
    "### Memory Problem\n",
    "\n",
    "The only problem with this approach is that the agent do not keep track of the flow. Hence, if you ask any follow up question, it doesn't remember and not answer you well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pnYDP65zJC3s"
   },
   "source": [
    "### Adding memory to our agent\n",
    "\n",
    "It is essential to integrate memory into your LLMs to maintain persistence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GNL7Ote-JCh2"
   },
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "\n",
    "# Define your agent and add this memory under 'checkpointer' parameter\n",
    "agent_executor = create_react_agent(llm, tools, checkpointer=memory, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EWC7j0WGQ8gq"
   },
   "outputs": [],
   "source": [
    "# Run the agent\n",
    "\n",
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content='What is btc?!')]}, config\n",
    "):\n",
    "    if 'agent' in chunk:\n",
    "      print(chunk['agent']['messages'][0].content)\n",
    "      print(\"----\")\n",
    "\n",
    "# Asking a follow up question.\n",
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content='Yes, I want to know how it works.')]}, config\n",
    "):\n",
    "    if 'agent' in chunk:\n",
    "      print(chunk['agent']['messages'][0].content)\n",
    "      print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQxHniNBRdOB"
   },
   "outputs": [],
   "source": [
    "# In case you're interested to see how the chunk looks like under the hood\n",
    "print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5M1aTk4QrvZu"
   },
   "source": [
    "## SQL Database Agent\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a93dc920"
   },
   "source": [
    "### Create sample database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b601f903"
   },
   "source": [
    "We will use the agents to interact with a small sample database of stocks. We will not dive into the details because this is just a dummy tool we will build for illustrative purposes. Let's create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "61b1f17c"
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import MetaData\n",
    "\n",
    "metadata_obj = MetaData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3cc1d80e"
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import Column, Integer, String, Table, Date, Float\n",
    "\n",
    "stocks = Table(\n",
    "    \"stocks\",\n",
    "    metadata_obj,\n",
    "    Column(\"obs_id\", Integer, primary_key=True),\n",
    "    Column(\"stock_ticker\", String(4), nullable=False),\n",
    "    Column(\"price\", Float, nullable=False),\n",
    "    Column(\"date\", Date, nullable=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c9a9571a"
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(\"sqlite:///:memory:\")\n",
    "metadata_obj.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "81c3081f"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "observations = [\n",
    "    [1, 'ABC', 200, datetime(2023, 1, 1)],\n",
    "    [2, 'ABC', 208, datetime(2023, 1, 2)],\n",
    "    [3, 'ABC', 232, datetime(2023, 1, 3)],\n",
    "    [4, 'ABC', 225, datetime(2023, 1, 4)],\n",
    "    [5, 'ABC', 226, datetime(2023, 1, 5)],\n",
    "    [6, 'XYZ', 810, datetime(2023, 1, 1)],\n",
    "    [7, 'XYZ', 803, datetime(2023, 1, 2)],\n",
    "    [8, 'XYZ', 798, datetime(2023, 1, 3)],\n",
    "    [9, 'XYZ', 795, datetime(2023, 1, 4)],\n",
    "    [10, 'XYZ', 791, datetime(2023, 1, 5)],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "85fd20fa"
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import insert\n",
    "\n",
    "def insert_obs(obs):\n",
    "    stmt = insert(stocks).values(\n",
    "    obs_id=obs[0],\n",
    "    stock_ticker=obs[1],\n",
    "    price=obs[2],\n",
    "    date=obs[3]\n",
    "    )\n",
    "\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6766f1f7"
   },
   "outputs": [],
   "source": [
    "for obs in observations:\n",
    "    insert_obs(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3_tIYndeNAt"
   },
   "source": [
    "### Building a SQL agent using `create_sql_agent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9721648e"
   },
   "outputs": [],
   "source": [
    "from langchain.utilities import SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "\n",
    "db = SQLDatabase(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mtm0N-57ryKh"
   },
   "outputs": [],
   "source": [
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.agents.agent_types import AgentType\n",
    "\n",
    "agent_executor = create_sql_agent(\n",
    "    llm=llm,\n",
    "    toolkit=SQLDatabaseToolkit(db=db, llm=llm),\n",
    "    verbose=True,\n",
    "    max_iterations=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FoZEC81PsuM7"
   },
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "def count_tokens(agent, query):\n",
    "    with get_openai_callback() as cb:\n",
    "        result = agent(query)\n",
    "        print(f'Spent a total of {cb.total_tokens} tokens')\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dEz1ML9LsJ4Z"
   },
   "outputs": [],
   "source": [
    "result = count_tokens(\n",
    "    agent_executor,\n",
    "    \"What is the multiplication of the ratio between stock \" +\n",
    "    \"prices for 'ABC' and 'XYZ' in January 3rd and the ratio \" +\n",
    "    \"between the same stock prices in January the 4th?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ujS6t3YryFz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "js-pwZlnZuom"
   },
   "source": [
    "## Arxiv Paper Summarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UclcqWTuaO8Y"
   },
   "source": [
    "This is how you can use the ArXiv tool to retrieve paper summaries on various topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MeNj2yqmZ2yD"
   },
   "outputs": [],
   "source": [
    "from langchain_community.agent_toolkits.load_tools import load_tools\n",
    "tools = load_tools([\"arxiv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "koT5-eZGZ2v4"
   },
   "outputs": [],
   "source": [
    "# Call arXiv\n",
    "print(tools[0].invoke(\"The attention is all you need\")[:250])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_HRFikca20D"
   },
   "source": [
    "Well, it's not the classic paper we're interested to learn about right. We could plug this tool to our agent and see if we can learn more about the attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "16ADTMZPaJB7"
   },
   "outputs": [],
   "source": [
    "agent = create_react_agent(llm, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I_2Zx0jCaI_e"
   },
   "outputs": [],
   "source": [
    "for event in agent.stream({\"messages\": [HumanMessage(content='what is attention in machine learning?')]}):\n",
    "      if event.get('tools'):\n",
    "        tool_call = event['tools']\n",
    "      print(event)\n",
    "      print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ongWqzF3d7ce"
   },
   "source": [
    "So as you can see our agent calls the tool and extracts necessary information and provides it to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JkOw6Ec8emDt"
   },
   "outputs": [],
   "source": [
    "# Tool call - You can find what info has been requested by the agent to the tool\n",
    "print(tool_call['messages'][0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Na6SIIKxeFKt"
   },
   "outputs": [],
   "source": [
    "print(event['agent']['messages'][0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NuNsVvXMZwWJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WKV3VrPOgv02"
   },
   "source": [
    "## Custom plot agent\n",
    "\n",
    "Lets build a custom agent that draws a line chart based on a given data.\n",
    "\n",
    "**Note:**\n",
    "* This agent may take atleast upto 2-3mins to run.\n",
    "* Re-run the cell in case it doesn't plot anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qq05vKeMfR_F"
   },
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data(data: str):\n",
    "    \"\"\"Plots the given data.\"\"\"\n",
    "    x, y = eval(data)\n",
    "    plt.plot(x, y)\n",
    "    plt.savefig(\"plot.png\")\n",
    "    return \"Plot saved as plot.png\"\n",
    "\n",
    "matplotlib_tool = Tool(\n",
    "    name=\"plot_data\",\n",
    "    func=plot_data,\n",
    "    description=\"Plots data using Matplotlib. Provide data as a list of tuples, e.g. '[(1, 2), (2, 4), (3, 6)]'\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QpfZZzHGf_9Z"
   },
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "plot_agent = create_react_agent(llm, [matplotlib_tool])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TZSHUrnegHUG"
   },
   "outputs": [],
   "source": [
    "for event in plot_agent.stream({\"messages\":[\"[(1, 2), (2, 4), (3, 6)]\"]}):\n",
    "\n",
    "      print(event)\n",
    "      print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I-ObNqapVyDR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rrCTZCF-rsAP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n6zWKt4err9t"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
