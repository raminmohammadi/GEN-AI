{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Assignment (Graded): Building a RAG System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to your programming assignment on Retrieval Augmented Generation (RAG)! You will build a comprehensive RAG system from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this assignment, you will build a complete RAG system that combines document retrieval and language model generation to create more accurate and contextual responses.\n",
    "- The system will implement document chunking, embedding generation, vector storage, similarity search, and response generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Document Processing Implementation**\n",
    "- Implement the `DocumentProcessor` class for handling various document formats\n",
    "- Add text extraction and cleaning methods\n",
    "- Implement document chunking with overlap\n",
    "- Handle metadata preservation\n",
    "\n",
    "**2. Embedding Generation**\n",
    "- Implement `EmbeddingGenerator` class with OpenAI integration\n",
    "- Add batch processing for embeddings\n",
    "- Implement caching mechanism\n",
    "- Add error handling and retry logic\n",
    "\n",
    "**3. Vector Store Integration**\n",
    "- Implement `VectorStore` class with FAISS integration\n",
    "- Add document indexing functionality\n",
    "- Implement similarity search methods\n",
    "- Add metadata filtering capabilities\n",
    "\n",
    "**4. Context Builder**\n",
    "- Implement `ContextBuilder` class\n",
    "- Add relevance scoring\n",
    "- Implement context window management\n",
    "- Add diversity sampling\n",
    "\n",
    "**5. Response Generator**\n",
    "- Implement `ResponseGenerator` class\n",
    "- Add prompt engineering\n",
    "- Implement source attribution\n",
    "- Add fact verification\n",
    "\n",
    "**6. RAG Pipeline Integration**\n",
    "- Implement the main `RAGSystem` class\n",
    "- Add pipeline orchestration\n",
    "- Implement caching and optimization\n",
    "- Add evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Only write code when you see any of the below prompts:\n",
    "    ```\n",
    "    # YOUR CODE GOES HERE\n",
    "    # YOUR CODE ENDS HERE\n",
    "    # TODO\n",
    "    ```\n",
    "- Do not modify any other section of the code unless stated otherwise in the comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional, Union\n",
    "import faiss\n",
    "import numpy as np\n",
    "import openai\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "from tests.test_methods import TestRAGSystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"FILL_IN_YOUR_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentProcessor:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the Document Processor\"\"\"\n",
    "        # TODO: Initialize document processing parameters\n",
    "        self.chunk_size = \n",
    "        self.chunk_overlap = \n",
    "        self.supported_formats = \n",
    "\n",
    "    def process_document(self, document: Union[str, bytes], format: str) -> List[Dict]:\n",
    "        \"\"\"Process document and return chunks with metadata\"\"\"\n",
    "        # TODO: Implement document processing\n",
    "        # TODO: Extract text based on format\n",
    "        # TODO: Clean and normalize text\n",
    "        # TODO: Split into chunks with overlap\n",
    "        # TODO: Preserve metadata\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingGenerator:\n",
    "    def __init__(self, api_key: str):\n",
    "        \"\"\"Initialize the Embedding Generator\"\"\"\n",
    "        # TODO: Initialize OpenAI client\n",
    "        # TODO: Set up caching\n",
    "        pass\n",
    "\n",
    "    def generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"Generate embeddings for given texts\"\"\"\n",
    "        # TODO: Implement batch embedding generation\n",
    "        # TODO: Add caching mechanism\n",
    "        # TODO: Implement retry logic\n",
    "        # TODO: Handle rate limits\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorStore:\n",
    "    def __init__(self, dimension: int):\n",
    "        \"\"\"Initialize the Vector Store\"\"\"\n",
    "        # TODO: Initialize FAISS index\n",
    "        # TODO: Set up metadata storage\n",
    "        pass\n",
    "\n",
    "    def add_documents(self, documents: List[Dict], embeddings: np.ndarray):\n",
    "        \"\"\"Add documents and their embeddings to the store\"\"\"\n",
    "        # TODO: Implement document indexing\n",
    "        # TODO: Store metadata\n",
    "        pass\n",
    "\n",
    "    def similarity_search(self, query_embedding: np.ndarray, k: int = 5) -> List[Dict]:\n",
    "        \"\"\"Perform similarity search\"\"\"\n",
    "        # TODO: Implement k-NN search\n",
    "        # TODO: Return documents with metadata\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextBuilder:\n",
    "    def __init__(self, max_tokens: int):\n",
    "        \"\"\"Initialize the Context Builder\"\"\"\n",
    "        # TODO: Set up context parameters\n",
    "        pass\n",
    "\n",
    "    def build_context(self, relevant_docs: List[Dict], query: str) -> str:\n",
    "        \"\"\"Build context from relevant documents\"\"\"\n",
    "        # TODO: Implement context selection\n",
    "        # TODO: Add relevance scoring\n",
    "        # TODO: Implement context truncation\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseGenerator:\n",
    "    def __init__(self, api_key: str):\n",
    "        \"\"\"Initialize the Response Generator\"\"\"\n",
    "        # TODO: Initialize OpenAI client\n",
    "        # TODO: Set up prompt templates\n",
    "        pass\n",
    "\n",
    "    def generate_response(self, query: str, context: str) -> Dict:\n",
    "        \"\"\"Generate response using context\"\"\"\n",
    "        # TODO: Implement response generation\n",
    "        # TODO: Add source attribution\n",
    "        # TODO: Implement fact verification\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGSystem:\n",
    "    def __init__(self, openai_api_key: str):\n",
    "        \"\"\"Initialize the RAG System\"\"\"\n",
    "        # TODO: Initialize all components\n",
    "        self.doc_processor = DocumentProcessor()\n",
    "        self.embedding_generator = EmbeddingGenerator(openai_api_key)\n",
    "        self.vector_store = VectorStore(1536)  # OpenAI embedding dimension\n",
    "        self.context_builder = ContextBuilder(max_tokens=2000)\n",
    "        self.response_generator = ResponseGenerator(openai_api_key)\n",
    "\n",
    "    def add_documents(self, documents: List[Union[str, bytes]], formats: List[str]):\n",
    "        \"\"\"Process and add documents to the system\"\"\"\n",
    "        # TODO: Implement document processing pipeline\n",
    "        # TODO: Generate embeddings\n",
    "        # TODO: Add to vector store\n",
    "        pass\n",
    "\n",
    "    def query(self, query: str) -> Dict:\n",
    "        \"\"\"Process query and generate response\"\"\"\n",
    "        # TODO: Implement query pipeline\n",
    "        # TODO: Generate query embedding\n",
    "        # TODO: Retrieve relevant documents\n",
    "        # TODO: Build context\n",
    "        # TODO: Generate response\n",
    "        pass\n",
    "\n",
    "    def evaluate(self, test_queries: List[str], ground_truth: List[str]) -> Dict:\n",
    "        \"\"\"Evaluate system performance\"\"\"\n",
    "        # TODO: Implement evaluation metrics\n",
    "        # TODO: Calculate accuracy\n",
    "        # TODO: Measure response time\n",
    "        # TODO: Assess relevance\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO NOT MODIFY THE BELOW CODE ##\n",
    "# Driver code for testing\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize system\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    rag_system = RAGSystem(api_key)\n",
    "\n",
    "    paper1 = \"\"\"The Impact of Artificial Intelligence on Modern Healthcare Systems\n",
    "\n",
    "Recent advances in artificial intelligence have revolutionized healthcare delivery and patient outcomes. Machine learning algorithms have demonstrated remarkable accuracy in diagnostic imaging, with success rates exceeding 95% in detecting early-stage cancers. Natural language processing systems are now capable of analyzing millions of medical records to identify patterns and treatment correlations that human researchers might miss.\n",
    "\n",
    "A particularly promising application is in predictive analytics for patient care. Studies conducted across 50 major hospitals showed that AI-powered systems reduced hospital readmission rates by 28% through early intervention recommendations. These systems analyze vital signs, medical history, and lifestyle factors to predict potential complications before they become severe.\n",
    "\n",
    "However, challenges remain in implementation. Data privacy concerns, integration with existing healthcare infrastructure, and the need for continuous model updating present significant hurdles. Healthcare providers must also ensure proper training for medical staff to effectively utilize these new tools while maintaining the human element in patient care.\n",
    "\"\"\"\n",
    "\n",
    "    paper2 = \"\"\"Quantum Computing: A Developer's Guide to QASM Implementation\n",
    "\n",
    "The Quantum Assembly Language (QASM) provides a fundamental interface for quantum circuit description and manipulation. This guide covers essential implementation details for quantum programs.\n",
    "\n",
    "Basic QASM Operations:\n",
    "1. Qubit initialization and reset procedures\n",
    "2. Single-qubit gates (X, Y, Z, H)\n",
    "3. Two-qubit controlled operations (CNOT, CZ)\n",
    "4. Measurement operations\n",
    "\n",
    "Error correction is crucial in quantum computing due to decoherence effects. The surface code implementation requires careful consideration of physical qubit layouts and error thresholds. When designing quantum circuits, developers must account for connectivity constraints and gate fidelity metrics.\n",
    "\n",
    "Performance optimization techniques include:\n",
    "- Circuit depth reduction through gate cancellation\n",
    "- Parallel gate execution where possible\n",
    "- Strategic qubit mapping to minimize SWAP operations\n",
    "- Measurement-based feed-forward operations\n",
    "\n",
    "Testing quantum programs requires both classical simulation for small circuits and hardware validation for scaled implementations. Use standard benchmarking protocols to verify gate fidelities and system coherence times.\n",
    "\"\"\"\n",
    "\n",
    "    # Test documents\n",
    "    documents = [\n",
    "       paper1,\n",
    "        paper2\n",
    "    ]\n",
    "    formats = [\"text\", \"text\"]\n",
    "\n",
    "    # Add documents\n",
    "    rag_system.add_documents(documents, formats)\n",
    "\n",
    "    # Test query\n",
    "    query = \"What information can you find about topic AI?\"\n",
    "    result = rag_system.query(query)\n",
    "\n",
    "    # Print results\n",
    "    print(\"\\nQuery Result:\")\n",
    "    print(json.dumps(result, indent=2))\n",
    "\n",
    "\n",
    "# Run tests\n",
    "tester = TestRAGSystem(rag_system)\n",
    "results = tester.run_all_tests()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
