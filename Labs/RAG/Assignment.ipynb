{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Assignment (Graded): Building a RAG System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to your programming assignment on Retrieval Augmented Generation (RAG)! You will build a comprehensive RAG system from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this assignment, you will build a complete RAG system that combines document retrieval and language model generation to create more accurate and contextual responses.\n",
    "- The system will implement document chunking, embedding generation, vector storage, similarity search, and response generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Document Processing Implementation**\n",
    "- Implement the `DocumentProcessor` class for handling various document formats\n",
    "- Add text extraction and cleaning methods\n",
    "- Implement document chunking with overlap\n",
    "- Handle metadata preservation\n",
    "\n",
    "**2. Embedding Generation**\n",
    "- Implement `EmbeddingGenerator` class with OpenAI integration\n",
    "- Add batch processing for embeddings\n",
    "- Implement caching mechanism\n",
    "- Add error handling and retry logic\n",
    "\n",
    "**3. Vector Store Integration**\n",
    "- Implement `VectorStore` class with FAISS integration\n",
    "- Add document indexing functionality\n",
    "- Implement similarity search methods\n",
    "- Add metadata filtering capabilities\n",
    "\n",
    "**4. Context Builder**\n",
    "- Implement `ContextBuilder` class\n",
    "- Add relevance scoring\n",
    "- Implement context window management\n",
    "- Add diversity sampling\n",
    "\n",
    "**5. Response Generator**\n",
    "- Implement `ResponseGenerator` class\n",
    "- Add prompt engineering\n",
    "- Implement source attribution\n",
    "- Add fact verification\n",
    "\n",
    "**6. RAG Pipeline Integration**\n",
    "- Implement the main `RAGSystem` class\n",
    "- Add pipeline orchestration\n",
    "- Implement caching and optimization\n",
    "- Add evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Only write code when you see any of the below prompts:\n",
    "    ```\n",
    "    # YOUR CODE GOES HERE\n",
    "    # YOUR CODE ENDS HERE\n",
    "    # TODO\n",
    "    ```\n",
    "- Do not modify any other section of the code unless stated otherwise in the comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional, Union\n",
    "import faiss\n",
    "import numpy as np\n",
    "import openai\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "from tests.test_methods import TestRAGSystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentProcessor:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the Document Processor\"\"\"\n",
    "        # TODO: Initialize document processing parameters\n",
    "        self.chunk_size = \n",
    "        self.chunk_overlap = \n",
    "        self.supported_formats = \n",
    "\n",
    "    def process_document(self, document: Union[str, bytes], format: str) -> List[Dict]:\n",
    "        \"\"\"Process document and return chunks with metadata\"\"\"\n",
    "        # TODO: Implement document processing\n",
    "        # TODO: Extract text based on format\n",
    "        # TODO: Clean and normalize text\n",
    "        # TODO: Split into chunks with overlap\n",
    "        # TODO: Preserve metadata\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingGenerator:\n",
    "    def __init__(self, api_key: str):\n",
    "        \"\"\"Initialize the Embedding Generator\"\"\"\n",
    "        # TODO: Initialize OpenAI client\n",
    "        # TODO: Set up caching\n",
    "        pass\n",
    "\n",
    "    def generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"Generate embeddings for given texts\"\"\"\n",
    "        # TODO: Implement batch embedding generation\n",
    "        # TODO: Add caching mechanism\n",
    "        # TODO: Implement retry logic\n",
    "        # TODO: Handle rate limits\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorStore:\n",
    "    def __init__(self, dimension: int):\n",
    "        \"\"\"Initialize the Vector Store\"\"\"\n",
    "        # TODO: Initialize FAISS index\n",
    "        # TODO: Set up metadata storage\n",
    "        pass\n",
    "\n",
    "    def add_documents(self, documents: List[Dict], embeddings: np.ndarray):\n",
    "        \"\"\"Add documents and their embeddings to the store\"\"\"\n",
    "        # TODO: Implement document indexing\n",
    "        # TODO: Store metadata\n",
    "        pass\n",
    "\n",
    "    def similarity_search(self, query_embedding: np.ndarray, k: int = 5) -> List[Dict]:\n",
    "        \"\"\"Perform similarity search\"\"\"\n",
    "        # TODO: Implement k-NN search\n",
    "        # TODO: Return documents with metadata\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextBuilder:\n",
    "    def __init__(self, max_tokens: int):\n",
    "        \"\"\"Initialize the Context Builder\"\"\"\n",
    "        # TODO: Set up context parameters\n",
    "        pass\n",
    "\n",
    "    def build_context(self, relevant_docs: List[Dict], query: str) -> str:\n",
    "        \"\"\"Build context from relevant documents\"\"\"\n",
    "        # TODO: Implement context selection\n",
    "        # TODO: Add relevance scoring\n",
    "        # TODO: Implement context truncation\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseGenerator:\n",
    "    def __init__(self, api_key: str):\n",
    "        \"\"\"Initialize the Response Generator\"\"\"\n",
    "        # TODO: Initialize OpenAI client\n",
    "        # TODO: Set up prompt templates\n",
    "        pass\n",
    "\n",
    "    def generate_response(self, query: str, context: str) -> Dict:\n",
    "        \"\"\"Generate response using context\"\"\"\n",
    "        # TODO: Implement response generation\n",
    "        # TODO: Add source attribution\n",
    "        # TODO: Implement fact verification\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGSystem:\n",
    "    def __init__(self, openai_api_key: str):\n",
    "        \"\"\"Initialize the RAG System\"\"\"\n",
    "        # TODO: Initialize all components\n",
    "        self.doc_processor = DocumentProcessor()\n",
    "        self.embedding_generator = EmbeddingGenerator(openai_api_key)\n",
    "        self.vector_store = VectorStore(1536)  # OpenAI embedding dimension\n",
    "        self.context_builder = ContextBuilder(max_tokens=2000)\n",
    "        self.response_generator = ResponseGenerator(openai_api_key)\n",
    "\n",
    "    def add_documents(self, documents: List[Union[str, bytes]], formats: List[str]):\n",
    "        \"\"\"Process and add documents to the system\"\"\"\n",
    "        # TODO: Implement document processing pipeline\n",
    "        # TODO: Generate embeddings\n",
    "        # TODO: Add to vector store\n",
    "        pass\n",
    "\n",
    "    def query(self, query: str) -> Dict:\n",
    "        \"\"\"Process query and generate response\"\"\"\n",
    "        # TODO: Implement query pipeline\n",
    "        # TODO: Generate query embedding\n",
    "        # TODO: Retrieve relevant documents\n",
    "        # TODO: Build context\n",
    "        # TODO: Generate response\n",
    "        pass\n",
    "\n",
    "    def evaluate(self, test_queries: List[str], ground_truth: List[str]) -> Dict:\n",
    "        \"\"\"Evaluate system performance\"\"\"\n",
    "        # TODO: Implement evaluation metrics\n",
    "        # TODO: Calculate accuracy\n",
    "        # TODO: Measure response time\n",
    "        # TODO: Assess relevance\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Driver code for testing\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize system\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    rag_system = RAGSystem(api_key)\n",
    "\n",
    "    # Test documents\n",
    "    documents = [\n",
    "        \"Example document 1 content\",\n",
    "        \"Example document 2 content\"\n",
    "    ]\n",
    "    formats = [\"text\", \"text\"]\n",
    "\n",
    "    # Add documents\n",
    "    rag_system.add_documents(documents, formats)\n",
    "\n",
    "    # Test query\n",
    "    query = \"What information can you find about topic X?\"\n",
    "    result = rag_system.query(query)\n",
    "\n",
    "    # Print results\n",
    "    print(\"\\nQuery Result:\")\n",
    "    print(json.dumps(result, indent=2))\n",
    "\n",
    "# Run tests\n",
    "tester = TestRAGSystem(rag_system)\n",
    "results = tester.run_all_tests()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
