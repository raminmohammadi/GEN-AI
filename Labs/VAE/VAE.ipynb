{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "    <h1>Variational Auto Encoders(VAEs)</h1>\n",
        "</center>"
      ],
      "metadata": {
        "id": "ePTJ548EONuN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Brief Recap\n",
        "\n",
        "VAEs are a generative model that learns a latent representation of data. Unlike traditional autoencoders, which learn a deterministic mapping between input and output, VAEs learn a probabilistic mapping that allows them to generate new data samples that are similar to the training data.\n",
        "\n",
        "This probabilistic nature is achieved by modeling the latent space as a probability distribution, typically a Gaussian distribution. The encoder maps the input to this distribution, and the decoder samples from the distribution to generate new data. This probabilistic formulation allows VAEs to capture the uncertainty in the data and generate more diverse and realistic samples.\n"
      ],
      "metadata": {
        "id": "6JpLigzlOWIe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VAE Architecture Description\n",
        "\n",
        "![VAE Architecture]('assets/vae.png')\n",
        "\n",
        "1. **Input:** This is the input data to the VAE, which can be any type of data such as images, text, or numerical data.\n",
        "\n",
        "2. **Encoder:** The encoder is a neural network that maps the input data to a latent space. It learns to extract the essential features and patterns from the input.\n",
        "\n",
        "3. **Mean μ and Std σ:** The encoder outputs the mean (μ) and standard deviation (σ) of a Gaussian distribution in the latent space. These values represent the parameters of the probability distribution that describes the input data.\n",
        "\n",
        "4. **Latent Space:** This is a lower-dimensional representation of the input data. It is a probabilistic space where each point represents a possible combination of the latent variables.\n",
        "\n",
        "5. **Sampling:** In this step, a random sample is drawn from the Gaussian distribution defined by the mean and standard deviation. This sampling process introduces randomness into the VAE, allowing it to generate new data points that are similar to the training data but not identical.\n",
        "\n",
        "6. **Decoder:** The decoder is a neural network that maps the sampled point from the latent space back to the original input space. It learns to reconstruct the input data based on the latent representation.\n",
        "\n",
        "Output: This is the reconstructed output of the VAE, which is the decoder's attempt to recreate the original input data based on the latent representation."
      ],
      "metadata": {
        "id": "AjzcBTOwOdy5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advantages of VAEs\n",
        "* **Generative Capabilities:** VAEs can generate new data samples that are similar to the training data.\n",
        "* **Probabilistic Interpretation:** The latent space is probabilistic, allowing for uncertainty modeling and more flexible representations.\n",
        "* **Regularization:** The KL divergence term in the loss function acts as a regularizer, preventing the model from collapsing to a degenerate solution.\n",
        "* **Improved Representation Learning:** VAEs can learn meaningful latent representations that capture the underlying structure of the data."
      ],
      "metadata": {
        "id": "0xKeRJctOiL1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building VAE model in TensorFlow\n",
        "\n"
      ],
      "metadata": {
        "id": "iEu3F362OltO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Lambda, Layer\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from helpers import *\n",
        "\n",
        "# Hyperparameters\n",
        "latent_dim = 40  # Dimensionality of the latent space\n",
        "batch_size = 128\n",
        "epochs = 100"
      ],
      "metadata": {
        "id": "NhUywLmbRhst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder network\n",
        "inputs = Input(shape=(784,))  # Assuming 28x28 input images flattened\n",
        "x = Dense(512, activation='relu')(inputs)\n",
        "x = Dense(latent_dim * 2)(x)  # Output mean and variance\n",
        "\n",
        "# Sampling layer from the latent space distribution\n",
        "z_mean = Lambda(lambda x: x[:, :latent_dim], output_shape=(latent_dim,))(x)\n",
        "z_log_var = Lambda(lambda x: x[:, latent_dim:], output_shape=(latent_dim,))(x)\n",
        "\n",
        "# Define a function to sample from the latent space\n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim))\n",
        "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "# Use the Lambda layer to create the sampling layer\n",
        "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
        "\n",
        "# Decoder network\n",
        "decoder_inputs = Input(shape=(latent_dim,))\n",
        "decoder_hidden = Dense(512, activation='relu')\n",
        "decoder_out = Dense(784, activation='sigmoid')\n",
        "\n",
        "decoder_x = decoder_hidden(decoder_inputs)\n",
        "outputs = decoder_out(decoder_x)\n",
        "\n",
        "# Build the decoder model separately for generating new samples later\n",
        "decoder = Model(decoder_inputs, outputs)\n",
        "\n",
        "# Apply the decoder to the sampled latent vector\n",
        "outputs = decoder(z)\n",
        "\n",
        "# VAE model: mapping inputs to the reconstructed outputs\n",
        "vae = Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "n4V3XAygQsyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae.summary()"
      ],
      "metadata": {
        "id": "CwxEqAlIR0f3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encoder network:**\n",
        "\n",
        "* `inputs = Input(shape=(784,))`: Creates an input layer for 784-dimensional input data (e.g., flattened 28x28 images).\n",
        "x = Dense(512, activation='relu')(inputs): Adds a hidden layer with 512 units and ReLU activation. This layer processes the input data and extracts features.\n",
        "* `x = Dense(latent_dim * 2)(x)`: Adds an output layer with latent_dim * 2 units. This layer outputs the mean and variance of the latent space distribution.\n",
        "\n",
        "**Sampling layer:**\n",
        "\n",
        "* `z_mean = Lambda(lambda x: x[:, :latent_dim], output_shape=(latent_dim,))(x)`: Extracts the mean of the latent space distribution from the output of the previous layer.\n",
        "* `z_log_var = Lambda(lambda x: x[:, latent_dim:], output_shape=(latent_dim,))(x)`: Extracts the log variance of the latent space distribution from the output of the previous layer.\n",
        "\n",
        "**Decoder network:**\n",
        "\n",
        "* `decoder_hidden = Dense(512, activation='relu')`: Adds a hidden layer with 512 units and ReLU activation. This layer processes the latent representation.\n",
        "* `decoder_out = Dense(784, activation='sigmoid')`: Adds an output layer with 784 units and sigmoid activation. This layer reconstructs the input data from the latent representation.\n",
        "* `decoder_inputs = Input(shape=(latent_dim,))`: Creates an input layer for the decoder, taking the sampled latent vector as input.\n",
        "* `decoder_x = decoder_hidden(decoder_inputs)`: Processes the latent vector using the decoder's hidden layer.\n",
        "* `outputs = decoder_out(decoder_x)`: The final output of the decoder, representing the reconstructed input.\n",
        "\n",
        "**VAE model:**\n",
        "\n",
        "* `vae = Model(inputs, outputs)`: Combines the encoder and decoder to form the complete VAE model.\n",
        "\n",
        "Overall, the code defines a VAE model with the following components:\n",
        "\n",
        "* Encoder: Maps the input data to a latent space, outputting the mean and variance of a Gaussian distribution.\n",
        "* Sampling layer: Samples a random point from the latent space distribution using the reparameterization trick.\n",
        "* Decoder: Reconstructs the input data from the sampled latent point.\n",
        "This VAE model can be used for various tasks such as generating new data, dimensionality reduction, and anomaly detection."
      ],
      "metadata": {
        "id": "fMjtUWZo12vk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building a DeNoising VAE on MNIST Dataset\n",
        "\n",
        "The MNIST (Modified National Institute of Standards and Technology) database is a widely used dataset in the field of machine learning, specifically for image classification tasks. It consists of 60,000 training images and 10,000 testing images, each 28x28 grayscale images of handwritten digits from 0 to 9. [(learn more)](https://www.tensorflow.org/datasets/catalog/mnist)\n",
        "\n",
        "The goal is to train a **Variational Autoencoder (VAE)** to denoise noisy MNIST images. This involves:\n",
        "\n",
        "* Adding noise to the clean MNIST images.\n",
        "* Training the VAE on these noisy images.\n",
        "* Using the trained VAE to denoise new noisy images.\n",
        "\n",
        "<img src='https://miro.medium.com/v2/resize:fit:1400/1*ZaC4kTerUL7Q1EEPtO7mWg.png' width=500>"
      ],
      "metadata": {
        "id": "JKrqwC_s6LDx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and Preprocess the dataset"
      ],
      "metadata": {
        "id": "lA7IhWg880QI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to [0, 1]\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255"
      ],
      "metadata": {
        "id": "2KJ7honS82M3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding Noise to the MNIST dataset"
      ],
      "metadata": {
        "id": "U-iR3bZO8V_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add noise to the training data\n",
        "noise_factor = 0.2  # Adjust noise level as needed\n",
        "x_train_noisy = x_train + noise_factor * np.random.normal(0, 1, x_train.shape)\n",
        "x_train_noisy = np.clip(x_train_noisy, 0., 1.)"
      ],
      "metadata": {
        "id": "biPcYBhk60WZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here `np.random.normal` where the values are derived from **Gaussian distribution** multiplied with `noise_factor` imputes **Gaussian noise** to the dataset."
      ],
      "metadata": {
        "id": "bVTIwOU_uJAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize original and noisy images\n",
        "fig, axs = plt.subplots(2, 5, figsize=(15, 6))\n",
        "for i in range(5):\n",
        "    axs[0, i].imshow(x_train[i], cmap='gray')\n",
        "    axs[0, i].set_title(f\"Original Image {i}\")\n",
        "    axs[1, i].imshow(x_train_noisy[i], cmap='gray')\n",
        "    axs[1, i].set_title(f\"Noisy Image {i}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WP6OSBEP67mY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape the input data before training\n",
        "x_train_noisy = x_train_noisy.reshape(-1, 784)  # Reshape to (num_samples, 784)\n",
        "x_train_noisy = x_train_noisy.astype('float32')\n",
        "x_train = x_train.reshape(-1, 784)\n",
        "x_test = x_test.reshape(-1, 784)\n",
        "\n",
        "# Print shapes for verification\n",
        "print(\"Original shape:\", x_train.shape)\n",
        "print(\"Noisy shape:\", x_train_noisy.shape)"
      ],
      "metadata": {
        "id": "TNOakMR5DDC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compiling and Training the VAE\n",
        "\n",
        " We shall be fitting the VAE model by minimizing the difference between the reconstructed images (from noisy input) and the original, clean images. The training process iterates through epochs, processing batches of data at a time, and uses the validation data to assess performance.\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "NKkQi--I3bOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vae.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError())"
      ],
      "metadata": {
        "id": "Dcy3CDwf3c4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the VAE\n",
        "vae.fit(x_train_noisy, x_train,\n",
        "        epochs=10,\n",
        "        batch_size=128,\n",
        "        validation_data=(x_test, x_test))"
      ],
      "metadata": {
        "id": "kfTjO8jZ3ic1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing the results"
      ],
      "metadata": {
        "id": "Sw-CALB3BApV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_denoised_images(vae, x_train, x_train_noisy, num_images=10)"
      ],
      "metadata": {
        "id": "E1iVLsKJTFvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mIx_PMzacPkB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}