{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1>Text to Image Generation with LLMs</h1>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brief Recap of Text to Image Generation with LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Text-to-image generation involves understanding the relationship between language (text input) and visual elements (image output).\n",
    "- DALL-E was trained on large-scale datasets of text-image pairs, enabling it to learn these associations effectively.\n",
    "\n",
    "- For example, when given a prompt like \"an astronaut riding a horse in space,\" DALL-E can produce an image that aligns with this imaginative concept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to DALL-E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DALL-E is a revolutionary AI model developed by OpenAI, designed to generate detailed and coherent images from textual descriptions.\n",
    "\n",
    "- It extends the capabilities of Large Language Models (LLMs) like GPT, moving beyond text generation to image synthesis.\n",
    "\n",
    "- The model interprets natural language prompts and transforms them into unique visual representations, making it highly versatile for creative and design applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Characteristics of DALL-E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- **Multimodal Learning**: DALL-E processes both text and visual data, bridging the gap between these two domains.\n",
    "\n",
    "- **Generative Creativity**: It can generate novel visual content, even for combinations of objects and attributes that do not exist in reality.\n",
    "\n",
    "- **High-Resolution Outputs**: The model is capable of producing high-quality, detailed images that accurately reflect the input prompt, making it suitable for a variety of use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"static/image1.gif\" alt=\"DALL-E\" style=\"width:50%;\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture Overview of DALL-E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DALL-E's architecture is built upon several key components that work together to generate images from textual prompts:\n",
    "\n",
    "- **Text Input Processing**:\n",
    "  - The input to DALL-E is a sequence of words that forms a prompt, which is tokenized and transformed into embeddings.\n",
    "  - **Tokenization**: The text is split into tokens, which are then converted into numerical representations using an embedding layer.\n",
    "  - **Positional Encoding**: Like other transformer models, DALL-E uses positional encoding to maintain the order and structure of the words in the sentence, which is crucial for understanding context.\n",
    "\n",
    "- **Image Decoding via Vector Quantized Variational AutoEncoder (VQ-VAE)**:\n",
    "  - **Discrete Image Representation**: Instead of generating pixel-by-pixel outputs, DALL-E breaks down an image into discrete tokens (image patches) using VQ-VAE. Each token represents a small part of the image, allowing the model to generate images more efficiently.\n",
    "  - **Latent Space**: The image is represented in a latent space where each token corresponds to a learned visual concept. The VQ-VAE helps map these tokens back to a complete image.\n",
    "\n",
    "- **Cross-Attention Mechanism**:\n",
    "  - DALL-E employs a cross-attention mechanism that aligns the text tokens (from the input) with the image tokens (being generated).\n",
    "  - This ensures that specific words or phrases from the prompt are linked to corresponding visual features, maintaining coherence between the description and the generated image.\n",
    "\n",
    "- **Transformer Decoder**:\n",
    "  - Similar to how transformers generate text in language models, DALL-E’s decoder generates sequences of image tokens, which are later decoded into the final visual output.\n",
    "  - This sequential token generation allows the model to create images with spatial coherence, ensuring that parts of the image fit together seamlessly (e.g., an astronaut’s helmet correctly placed on their head).\n",
    "\n",
    "- **Training**:\n",
    "  - DALL-E is trained on a massive dataset of text-image pairs using autoregressive modeling. The model learns to predict the next visual token given the previous tokens and the text prompt.\n",
    "  - During training, the objective is to minimize the difference between the generated image and the true image associated with the text input, allowing the model to generate accurate visual representations.\n",
    "\n",
    "- **Generation Process**:\n",
    "  - Once trained, DALL-E can generate images by taking a new text prompt, processing it through its transformer layers, and outputting a sequence of visual tokens. These tokens are then decoded back into a full image that corresponds to the input description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"static/image2.jpg\" alt=\"DALL-E Architecture\" style=\"width:50%;\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Major Advantages of DALL-E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **1. Creativity and Flexibility**:\n",
    "  - DALL-E excels at producing creative and original images from diverse text inputs, making it highly useful for design, art, and advertising.\n",
    "  - It can combine concepts that don’t normally coexist, such as “a cat dressed as a king,” creating visually imaginative outputs that are difficult to achieve with traditional models.\n",
    "  - The flexibility of DALL-E allows it to interpret and generate content even for prompts that involve abstract or complex scenarios, enhancing its creative potential.\n",
    "\n",
    "- **2. High-Quality and Detail**:\n",
    "  - DALL-E generates high-fidelity images with intricate details that closely align with the provided text.\n",
    "  - The model captures fine visual elements, from color schemes to object placement, ensuring that even nuanced descriptions are reflected in the output.\n",
    "  - This capability is particularly valuable in fields like marketing, product design, and digital content creation, where visual quality is critical.\n",
    "\n",
    "- **3. Generalization to Unseen Concepts**:\n",
    "  - Unlike models restricted to specific image categories, DALL-E can generalize to novel combinations of objects and attributes, allowing it to generate content for previously unseen prompts.\n",
    "  - This is achieved through its training on diverse text-image pairs, which helps the model learn broad visual-linguistic relationships.\n",
    "\n",
    "- **4. Multimodal Integration**:\n",
    "  - DALL-E effectively integrates language understanding with visual generation, providing an end-to-end solution for multimodal tasks.\n",
    "  - This makes it useful for applications that require both textual and visual outputs, such as creating interactive content or generating visuals for storytelling.\n",
    "\n",
    "- **5. Scalability**:\n",
    "  - The architecture of DALL-E is scalable, meaning it can handle increasingly complex prompts and generate more detailed images as the model size and dataset grow.\n",
    "  - As DALL-E is exposed to more data and larger models, it can continue to improve its ability to generate diverse and high-quality images from varied and complex text inputs.\n",
    "\n",
    "- **6. Applicability Across Industries**:\n",
    "  - DALL-E’s ability to generate images from text has broad applicability, from aiding in content creation and advertising to being used in education, healthcare, and entertainment.\n",
    "  - For example, in product design, DALL-E can quickly generate visual prototypes based on verbal descriptions, saving time and resources in the design process.\n",
    "  - In the gaming and entertainment industry, DALL-E can generate concept art or in-game assets based on creative prompts, enhancing the speed and diversity of content production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interacting with DALL-E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create an OpenAI Account\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Visit OpenAI's website (https://openai.com)\n",
    "2. Click on \"Sign Up\" or \"Get Started\"\n",
    "3. Enter your email address\n",
    "4. Create a secure password\n",
    "5. Verify your email through the confirmation link sent to your inbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Complete Account Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fill in your user profile information\n",
    "2. Provide your full name\n",
    "3. Set up two-factor authentication (recommended)\n",
    "4. Complete any additional verification steps if prompted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Set Up Billing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Navigate to the API section in your dashboard\n",
    "2. Click on \"Billing\" in the left sidebar\n",
    "3. Click \"Set up paid account\"\n",
    "4. Add a payment method (credit card required)\n",
    "5. Set usage limits (recommended to avoid unexpected charges)\n",
    "6. Consider setting a monthly spending cap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Generate API Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Go to the API Keys section in your dashboard\n",
    "2. Click \"Create new secret key\"\n",
    "3. Give your key a descriptive name\n",
    "4. Copy and save the API key immediately (it won't be shown again)\n",
    "5. Store the key securely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Configure Development Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Install required Python packages:\n",
    "    ```bash\n",
    "    pip install openai requests pillow\n",
    "    ```\n",
    "\n",
    "2. Set up your development environment with the API key:\n",
    "    ```python\n",
    "    from openai import OpenAI\n",
    "\n",
    "    client = OpenAI(api_key='your-api-key-here')\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Test DALL-E Access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a simple test script:\n",
    "    ```python\n",
    "    response = client.images.generate(\n",
    "        prompt=\"a simple test image\",\n",
    "        n=1,\n",
    "        size=\"1024x1024\"\n",
    "    )\n",
    "    image_url = response.data[0].url\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Understanding Usage and Pricing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Each image generation costs credits\n",
    "2. Monitor your usage in the dashboard\n",
    "3. Be aware of different size options and their costs:\n",
    "   - 1024x1024 (standard size)\n",
    "   - 1024x1792 or 1792x1024 (rectangular options)\n",
    "   - HD quality available for higher quality outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Build a sample project to understand the concept of Text to Image Generation with DALL-E better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: AI Art Gallery Creator - Learning DALL-E Image Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This hands-on project will introduce you to AI-powered image generation using DALL-E-3, teaching fundamental concepts of API integration, image processing, and modern AI applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Class Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Config` class is designed to manage configuration settings for the DALL-E API integration. Here's a detailed breakdown:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def __init__(self):\n",
    "    self._api_key = None\n",
    "    self.default_image_size = \"1024x1024\"\n",
    "    self.default_quality = \"standard\"\n",
    "    self.default_model = \"dall-e-3\"\n",
    "    self.output_directory = \"generated_images\"\n",
    "```\n",
    "\n",
    "**Instance Variables:**\n",
    "- `self._api_key`: Private variable (denoted by underscore) to store the OpenAI API key securely\n",
    "- `self.default_image_size`: Sets default image dimensions to 1024x1024 pixels\n",
    "- `self.default_quality`: Sets image quality to \"standard\" (alternatives: \"hd\")\n",
    "- `self.default_model`: Uses DALL-E 3 as the default model\n",
    "- `self.output_directory`: Specifies where generated images will be saved\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Key Property"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "@property\n",
    "def api_key(self):\n",
    "    if not self._api_key:\n",
    "        raise ValueError(\"API key not set. Call set_api_key() first.\")\n",
    "    return self._api_key\n",
    "```\n",
    "\n",
    "**Key Features:**\n",
    "- Uses Python's `@property` decorator for controlled access to the API key\n",
    "- Implements a getter method that checks if the API key is set\n",
    "- Raises an error if attempting to access an unset API key\n",
    "- Provides secure access to the private `_api_key` variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Key Setter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def set_api_key(self, key):\n",
    "    self._api_key = key\n",
    "```\n",
    "\n",
    "**Functionality:**\n",
    "- Simple method to set the API key\n",
    "- Takes a single parameter `key` which is the OpenAI API key\n",
    "- Assigns the key to the private `_api_key` variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Notes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Security:**\n",
    "   - The API key is stored in a private variable\n",
    "   - Access is controlled through property decorator\n",
    "   - Prevents direct modification of the API key\n",
    "\n",
    "2. **Default Settings:**\n",
    "   - Image size: 1024x1024 (square format)\n",
    "   - Quality: standard (balanced option)\n",
    "   - Model: DALL-E 3 (latest version)\n",
    "\n",
    "3. **Best Practices:**\n",
    "   - Always set the API key before attempting to use the configuration\n",
    "   - Use the property getter to access the API key\n",
    "   - Don't modify the API key directly through the private variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self._api_key = None\n",
    "        self.default_image_size = \"1024x1024\"\n",
    "        self.default_quality = \"standard\"\n",
    "        self.default_model = \"dall-e-3\"\n",
    "        self.output_directory = \"generated_images\"\n",
    "\n",
    "    @property\n",
    "    def api_key(self):\n",
    "        if not self._api_key:\n",
    "            raise ValueError(\"API key not set. Call set_api_key() first.\")\n",
    "        return self._api_key\n",
    "\n",
    "    def set_api_key(self, key):\n",
    "        self._api_key = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DallEDemo Class Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class serves as the main interface for interacting with DALL-E's image generation capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def __init__(self, config: Config):\n",
    "    self.config = config\n",
    "    self.client = OpenAI(api_key=self.config.api_key)\n",
    "    self.output_dir = self.config.output_directory\n",
    "    os.makedirs(self.output_dir, exist_ok=True)\n",
    "```\n",
    "\n",
    "**Parameters:**\n",
    "- `config`: Configuration object containing API key and settings\n",
    "- Creates OpenAI client instance\n",
    "- Sets up output directory for saving images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Generation Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def generate_image(self, prompt, size=None, quality=None, n=1):\n",
    "```\n",
    "\n",
    "**Parameters:**\n",
    "- `prompt`: Text description for the image to generate\n",
    "- `size`: Optional image dimensions (e.g., \"1024x1024\", \"1024x1792\")\n",
    "- `quality`: Optional image quality (\"standard\" or \"hd\")\n",
    "- `n`: Number of images to generate (default: 1)\n",
    "\n",
    "\n",
    "**Implementation Details:**\n",
    "```python\n",
    "response = self.client.images.generate(\n",
    "    model=self.config.default_model,\n",
    "    prompt=prompt,\n",
    "    size=size or self.config.default_image_size,\n",
    "    quality=quality or self.config.default_quality,\n",
    "    n=n\n",
    ")\n",
    "```\n",
    "\n",
    "**Returns:**\n",
    "- `image_path`: Path to saved image\n",
    "- `revised_prompt`: DALL-E's interpretation of the input prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variation Creation Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def create_variation(self, image_path, n=1, size=None):\n",
    "```\n",
    "\n",
    "**Parameters:**\n",
    "- `image_path`: Path to source image\n",
    "- `n`: Number of variations (default: 1)\n",
    "- `size`: Optional size for variations\n",
    "\n",
    "**Implementation Details:**\n",
    "```python\n",
    "response = self.client.images.create_variation(\n",
    "    model=\"dall-e-2\",\n",
    "    image=open(image_path, \"rb\"),\n",
    "    n=n,\n",
    "    size=size or self.config.default_image_size\n",
    ")\n",
    "```\n",
    "\n",
    "**Returns:**\n",
    "- List of paths to generated variation images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Saving Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def _save_image(self, image_url, filename):\n",
    "```\n",
    "\n",
    "**Parameters:**\n",
    "- `image_url`: URL of the generated image\n",
    "- `filename`: Name for saving the image\n",
    "\n",
    "**Implementation:**\n",
    "- Downloads image from URL using requests\n",
    "- Saves to specified output directory\n",
    "- Returns path to saved image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Display Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def display_image(self, image_path):\n",
    "```\n",
    "\n",
    "**Parameters:**\n",
    "- `image_path`: Path to image file\n",
    "\n",
    "**Implementation:**\n",
    "- Opens image using PIL\n",
    "- Displays using matplotlib\n",
    "- Configures display settings (10x10 figure size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DallEDemo:\n",
    "    def __init__(self, config: Config):\n",
    "        \"\"\"\n",
    "        Initialize DALL-E Demo with configuration\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.client = OpenAI(api_key=self.config.api_key)\n",
    "        self.output_dir = self.config.output_directory\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "\n",
    "    def generate_image(self, prompt, size=None, quality=None, n=1):\n",
    "        \"\"\"\n",
    "        Generate an image using DALL-E 3\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = self.client.images.generate(\n",
    "                model=self.config.default_model,\n",
    "                prompt=prompt,\n",
    "                size=size or self.config.default_image_size,\n",
    "                quality=quality or self.config.default_quality,\n",
    "                n=n\n",
    "            )\n",
    "            \n",
    "            image_url = response.data[0].url\n",
    "            image_path = self._save_image(image_url, f\"generated_{len(os.listdir(self.output_dir))}.png\")\n",
    "            return image_path, response.data[0].revised_prompt\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating image: {e}\")\n",
    "            return None, None\n",
    "\n",
    "    def create_variation(self, image_path, n=1, size=None):\n",
    "        \"\"\"\n",
    "        Create variations of an existing image\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = self.client.images.create_variation(\n",
    "                model=\"dall-e-2\",  # DALL-E 2 for variations\n",
    "                image=open(image_path, \"rb\"),\n",
    "                n=n,\n",
    "                size=size or self.config.default_image_size\n",
    "            )\n",
    "            \n",
    "            variations = []\n",
    "            for i, data in enumerate(response.data):\n",
    "                image_path = self._save_image(\n",
    "                    data.url, \n",
    "                    f\"variation_{len(os.listdir(self.output_dir))}_{i}.png\"\n",
    "                )\n",
    "                variations.append(image_path)\n",
    "            return variations\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error creating variations: {e}\")\n",
    "            return None\n",
    "\n",
    "    def _save_image(self, image_url, filename):\n",
    "        \"\"\"\n",
    "        Save image from URL to local file\n",
    "        \"\"\"\n",
    "        response = requests.get(image_url)\n",
    "        image_path = os.path.join(self.output_dir, filename)\n",
    "        \n",
    "        with open(image_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        return image_path\n",
    "\n",
    "    def display_image(self, image_path):\n",
    "        \"\"\"\n",
    "        Display an image using matplotlib\n",
    "        \"\"\"\n",
    "        img = Image.open(image_path)\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    try:\n",
    "        # Initialize configuration\n",
    "        config = Config()\n",
    "        \n",
    "        # Set API key\n",
    "        api_key = input(\"Please enter your OpenAI API key: \").strip()\n",
    "        config.set_api_key(api_key)\n",
    "        \n",
    "        # Initialize DALL-E demo with config\n",
    "        demo = DallEDemo(config)\n",
    "        \n",
    "        # Generate image\n",
    "        print(\"\\nGenerating new image...\")\n",
    "        prompt = \"A futuristic city with flying cars and neon lights\"\n",
    "        image_path, revised_prompt = demo.generate_image(prompt)\n",
    "        \n",
    "        if image_path:\n",
    "            print(f\"Original prompt: {prompt}\")\n",
    "            print(f\"Revised prompt: {revised_prompt}\")\n",
    "            print(f\"Image saved to: {image_path}\")\n",
    "            demo.display_image(image_path)\n",
    "        \n",
    "        # Create variations\n",
    "        if image_path:\n",
    "            print(\"\\nCreating variations...\")\n",
    "            variations = demo.create_variation(image_path, n=2)\n",
    "            if variations:\n",
    "                print(f\"Created {len(variations)} variations\")\n",
    "                for var_path in variations:\n",
    "                    demo.display_image(var_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        print(\"\\nTroubleshooting steps:\")\n",
    "        print(\"1. Make sure your API key is correct\")\n",
    "        print(\"2. Check your internet connection\")\n",
    "        print(\"3. Verify you have sufficient API credits\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
