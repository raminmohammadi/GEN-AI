{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1>Generative Adversarial Networks (GAN)</h1>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brief Recap of Generative Adversarial Networks (GANs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generative Adversarial Networks (GANs) are a class of deep learning models introduced by Ian Goodfellow and his colleagues in 2014.\n",
    "\n",
    "- GANs consist of two neural networks that are trained simultaneously in a competitive process:\n",
    "\n",
    "    1. **Generator**: This network learns to create data (e.g., images) that resembles the training data.\n",
    "    \n",
    "    2. **Discriminator**: This network learns to distinguish between real data from the training set and fake data produced by the generator.\n",
    "\n",
    "- The two networks are locked in a constant battle, with the generator trying to produce increasingly realistic data to fool the discriminator, and the discriminator becoming better at detecting fake data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generative Adversarial Networks (GANs) consist of two main components: the Generator and the Discriminator.\n",
    "\n",
    "- These two neural networks work in tandem to create a powerful generative model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do GANs work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training process of GANs can be likened to a game between a counterfeiter (generator) and a detective (discriminator):\n",
    "\n",
    "1. The generator creates fake data from random noise.\n",
    "\n",
    "2. The discriminator is presented with both real and fake data and tries to distinguish between them.\n",
    "3. Based on the discriminator's feedback, the generator adjusts its parameters to produce more convincing fakes.\n",
    "4. This process continues iteratively, with both networks improving over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"static/image2.gif\" alt=\"GAN Workflow\" style=\"width:50%;\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Generator is responsible for creating synthetic data that resembles the training dataset.\n",
    "\n",
    "**Structure:**\n",
    "\n",
    "- Input Layer: Takes random noise as input.\n",
    "\n",
    "- Hidden Layers: A series of dense and transposed convolutional layers that progressively upsample the input.\n",
    "- Output Layer: Produces an image of the desired size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Discriminator acts as a binary classifier, distinguishing between real images from the dataset and fake images produced by the Generator.\n",
    "\n",
    "**Structure:**\n",
    "\n",
    "- Input Layer: Takes an image as input.\n",
    "\n",
    "- Hidden Layers: A series of convolutional layers that downsample the input.\n",
    "- Output Layer: A single neuron that outputs the probability of the input being real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"static/image1.png\" alt=\"GAN Workflow\" style=\"width:50%;\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges in Training GANs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While powerful, GANs are notoriously difficult to train due to several challenges:\n",
    "\n",
    "- **Mode Collapse**: The generator may learn to produce only a limited variety of outputs.\n",
    "\n",
    "- **Convergence Issues**: Finding the right balance between the generator and discriminator can be tricky.\n",
    "- **Evaluation Metrics**: Quantitatively assessing the quality of generated samples is challenging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications of GANs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GANs have found numerous applications across various fields:\n",
    "\n",
    "- **Image Generation**: Creating realistic images, artwork, and even faces of non-existent people.\n",
    "\n",
    "- **Image-to-Image Translation**: Transforming images from one domain to another (e.g., sketches to photos, day to night scenes).\n",
    "- **Super-Resolution**: Enhancing the resolution and quality of low-resolution images.\n",
    "- **Text-to-Image Synthesis**: Generating images based on textual descriptions.\n",
    "- **Data Augmentation**: Creating synthetic data to enhance training datasets for other machine learning models.\n",
    "\n",
    "\n",
    "In this notebook, we'll implement a basic GAN architecture to generate handwritten digits similar to those in the MNIST dataset. Through this process, we'll explore the fundamental concepts and challenges of training GANs using TensorFlow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing GANs with Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The create_generator_model() function defines the architecture of the generator in our GAN. Let's break it down:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "# Sample code to create a generator model\n",
    "def create_generator_model():\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(16, input_dim=100, activation='relu'),\n",
    "        keras.layers.Dense(32, activation='relu'),\n",
    "        keras.layers.Dense(2, activation='linear')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function creates a sequential model using Keras, which is a linear stack of layers. Here's what each layer does:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Input Layer**: \n",
    "   ```python\n",
    "   keras.layers.Dense(16, input_dim=100, activation='relu')\n",
    "   ```\n",
    "   - This is the first layer of the generator.\n",
    "   \n",
    "   - It takes an input of dimension 100 (typically random noise).\n",
    "   - It has 16 neurons (units) and uses the ReLU activation function.\n",
    "   - The ReLU function helps introduce non-linearity, allowing the model to learn complex patterns.\n",
    "   - For more information about the Dense Layer, refer this link: [Tensorflow Dense Layer Documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Hidden Layer**:\n",
    "   ```python\n",
    "   keras.layers.Dense(32, activation='relu')\n",
    "   ```\n",
    "   - This is a hidden layer with 32 neurons.\n",
    "   \n",
    "   - It also uses the ReLU activation function.\n",
    "   - This layer helps the model learn more complex representations of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Output Layer**:\n",
    "   ```python\n",
    "   keras.layers.Dense(2, activation='linear')\n",
    "   ```\n",
    "   - This is the output layer of the generator.\n",
    "\n",
    "   - It has 2 neurons, corresponding to the two dimensions of our generated data points.\n",
    "   - It uses a linear activation function, which means it outputs raw values without any transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this generator in your GAN:\n",
    "\n",
    "1. Create an instance of the model:\n",
    "   ```python\n",
    "   generator = make_generator_model()\n",
    "   ```\n",
    "\n",
    "2. You can then use this generator to produce fake samples:\n",
    "   ```python\n",
    "   noise = tf.random.normal([batch_size, 100])\n",
    "   generated_samples = generator(noise, training=True)\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Points::**\n",
    "- The generator's task is to transform the random input noise (100-dimensional vector) into a 2-dimensional point that resembles the real data distribution. \n",
    "\n",
    "- As the GAN training progresses, the generator will learn to produce points that will be increasingly similar to the real data.\n",
    "\n",
    "- This generator architecture is relatively simple, suitable for generating 2D Gaussian data. For more complex data (like images), you would typically use a more sophisticated architecture, possibly including convolutional layers for upsampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discriminator in a GAN is responsible for distinguishing between real data samples and fake samples generated by the generator. Let's examine its architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discriminator_model():\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(32, input_dim=2, activation='relu'),\n",
    "        keras.layers.Dense(16, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function creates a sequential model for the discriminator. Let's break down each layer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Input Layer:**\n",
    "```python\n",
    "keras.layers.Dense(32, input_dim=2, activation='relu')\n",
    "```\n",
    "- This is the input layer of the discriminator.\n",
    "\n",
    "- It expects input data with 2 dimensions, corresponding to our 2D Gaussian data points.\n",
    "- It has 32 neurons and uses the ReLU activation function.\n",
    "- The ReLU function introduces non-linearity, allowing the model to learn complex patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Hidden Layer**\n",
    "```python\n",
    "keras.layers.Dense(16, activation='relu')\n",
    "```\n",
    "- This is a hidden layer with 16 neurons.\n",
    "\n",
    "- It also uses the ReLU activation function.\n",
    "- This layer helps the model learn more sophisticated representations of the input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Output Layer**\n",
    "```python\n",
    "keras.layers.Dense(1, activation='sigmoid')\n",
    "```\n",
    "- This is the output layer of the discriminator.\n",
    "\n",
    "- It has a single neuron, which outputs a probability between 0 and 1.\n",
    "- The sigmoid activation function is used to squash the output into this probability range.\n",
    "- An output close to 1 indicates the discriminator believes the input is real, while an output close to 0 suggests it thinks the input is fake.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this discriminator in your GAN:\n",
    "\n",
    "1. Create an instance of the model:\n",
    "   ```python\n",
    "   discriminator = make_discriminator_model()\n",
    "   ```\n",
    "\n",
    "2. You can then use this discriminator to classify real and fake samples:\n",
    "   ```python\n",
    "   real_output = discriminator(real_samples, training=True)\n",
    "   fake_output = discriminator(generated_samples, training=True)\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Points:**\n",
    "\n",
    "- The discriminator's role is to learn to distinguish between the real data points and the fake points produced by the generator.\n",
    "\n",
    "- As training progresses, the discriminator should become better at this task, which in turn forces the generator to produce more realistic samples.\n",
    "- This architecture is suitable for 2D data. For more complex data types, such as images, you would typically use a more sophisticated architecture, possibly including convolutional layers for feature extraction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Build a Real world Project to understand the concept of GANs better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The MNSIT Handwritten Digit Recognition Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Features:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Content**: 70,000 grayscale images of handwritten digits (0-9)\n",
    "\n",
    "- **Image Size**: 28x28 pixels\n",
    "- **Split**: 60,000 training images, 10,000 test images\n",
    "- For more information about the dataset, refer to this link: [Tensorflow MNSIT Dataset](https://www.tensorflow.org/datasets/catalog/mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Challenge:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll use MNIST to train a Generative Adversarial Network (GAN). Our goal is to create a model that can generate new, realistic handwritten digits that resemble those in the MNIST dataset.\n",
    "\n",
    "This project will demonstrate:\n",
    "- Data preprocessing for GANs\n",
    "\n",
    "- Designing generator and discriminator networks\n",
    "- Training adversarial models\n",
    "- Evaluating generated images\n",
    "\n",
    "By working with MNIST, we'll gain practical experience in building and training GANs, a powerful class of generative models in deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing the data for GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "\n",
    "print(\"Training data shape:\", x_train.shape)\n",
    "print(\"Test data shape:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, for learning purposes, we'll be using a subset of the dataset for training our model and testing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a subset of the data (e.g., 10% for training, 5% for testing)\n",
    "x_train = x_train[:6000]\n",
    "x_test = x_test[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing pixel values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below code, we normalize the pixel values of the MNIST images to the range [-1, 1]. Below are the reasons, why this is important:\n",
    "\n",
    "- Consistent Scale: It ensures all pixel values are on the same scale, which helps the neural network learn more effectively.\n",
    "\n",
    "- Centered Data: By subtracting 127.5, we center the data around zero, which can improve training stability.\n",
    "- Range [-1, 1]: This range is particularly useful for GANs, as the generator's output layer often uses a tanh activation, which produces values in this range.\n",
    "- Improved Gradient Flow: Normalized data can lead to better gradient flow during backpropagation, potentially speeding up training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the images to [-1, 1]\n",
    "x_train = (x_train.astype('float32') - 127.5) / 127.5\n",
    "x_test = (x_test.astype('float32') - 127.5) / 127.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding channel dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below code, we include a channel dimension for:\n",
    "\n",
    "- Convolutional Layers: Most deep learning frameworks, including TensorFlow, expect input images for convolutional layers to have a shape of (height, width, channels).\n",
    "\n",
    "- Grayscale Images: MNIST images are grayscale, so we add a single channel. For color images, this would typically be 3 channels (RGB).\n",
    "\n",
    "- Compatibility: This reshaping ensures our data is compatible with the input shape expected by our GAN models.\n",
    "- Consistency: By applying this to both training and test sets, we maintain consistency across our dataset.\n",
    "\n",
    "- The resulting shape for each image becomes (28, 28, 1), where:\n",
    "    - 28 is the height of the image\n",
    "    - 28 is the width of the image\n",
    "    - 1 is the number of channels (grayscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add channel dimension\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below code, we create a dataset from our training data:\n",
    "\n",
    "- tf.data.Dataset: This is TensorFlow's API for building efficient input pipelines. It allows for fast data loading and preprocessing.\n",
    "\n",
    "- from_tensor_slices(): This function creates a dataset from our training data (x_train). It allows us to work with our data in smaller, manageable pieces.\n",
    "\n",
    "- shuffle():\n",
    "    - BUFFER_SIZE = 6000: This determines how many elements from the dataset it will buffer for shuffling.\n",
    "    - Shuffling helps prevent the model from learning the order of the training data, which could lead to overfitting.\n",
    "\n",
    "- batch():\n",
    "    - BATCH_SIZE = 64: This sets how many images will be processed in each training step.\n",
    "    - Batching allows for more efficient computation and helps in stabilizing the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tf.data.Dataset\n",
    "BUFFER_SIZE = 6000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below architecture progressively upsamples the input noise to generate a 28x28 pixel image, suitable for the MNIST dataset. The use of transposed convolutions allows the model to learn upsampling, effectively reversing the process of a typical convolutional network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Components:**\n",
    "- Input: Takes a 100-dimensional noise vector.\n",
    "\n",
    "- Dense Layer: Expands the input to 7x7x256, preparing for reshaping.\n",
    "- Reshape: Converts the dense output to a 3D shape for convolutional processing.\n",
    "- Transposed Convolutions: Used for upsampling, increasing the image size.\n",
    "- Batch Normalization: Stabilizes learning by normalizing layer inputs.\n",
    "- LeakyReLU: Activation function that allows a small gradient for negative inputs.\n",
    "- Output: A single channel image (28x28x1) with tanh activation, producing values in [-1, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = keras.Sequential([\n",
    "        # Input layer\n",
    "        keras.layers.Dense(7*7*256, use_bias=False, input_shape=(100,)),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.LeakyReLU(),\n",
    "        \n",
    "        # Reshape to start the convolutional structure\n",
    "        keras.layers.Reshape((7, 7, 256)),\n",
    "        \n",
    "        # First upsampling block\n",
    "        keras.layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.LeakyReLU(),\n",
    "        \n",
    "        # Second upsampling block\n",
    "        keras.layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.LeakyReLU(),\n",
    "        \n",
    "        # Output layer\n",
    "        keras.layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below architecture progressively reduces the spatial dimensions of the input while increasing the number of feature channels. The final dense layer outputs a single value, which can be interpreted as the discriminator's confidence that the input image is real (after applying a sigmoid activation, which is typically done in the loss function)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Components:**\n",
    "- Input: Accepts 28x28x1 images (MNIST format).\n",
    "\n",
    "- Convolutional Layers: Extract features from the input images.\n",
    "    - First layer: 64 filters\n",
    "    - Second layer: 128 filters\n",
    "    - Both use 5x5 kernels and stride of 2 for downsampling\n",
    "\n",
    "- LeakyReLU: Activation function that allows a small gradient for negative inputs, helping with the learning process.\n",
    "\n",
    "- Dropout: Helps prevent overfitting by randomly setting input units to 0 during training.\n",
    "\n",
    "- Flatten: Converts the 2D feature maps to a 1D vector for the dense layer.\n",
    "\n",
    "- Dense Output: Single neuron output, representing the probability of the input being real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = keras.Sequential([\n",
    "        # First convolutional layer\n",
    "        keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]),\n",
    "        keras.layers.LeakyReLU(),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        \n",
    "        # Second convolutional layer\n",
    "        keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'),\n",
    "        keras.layers.LeakyReLU(),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        \n",
    "        # Flatten the output\n",
    "        keras.layers.Flatten(),\n",
    "        \n",
    "        # Output layer\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the generator and discriminator models\n",
    "generator = make_generator_model()\n",
    "discriminator = make_discriminator_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a GAN, we need separate loss functions for the discriminator and the generator. These functions guide the training process for each network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use binary cross-entropy as our base loss function. The from_logits=True parameter indicates that the model output hasn't been passed through a sigmoid function yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss functions\n",
    "cross_entropy = keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminator Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discriminator loss measures how well the discriminator can distinguish between real and fake images:\n",
    "\n",
    "- real_loss: Calculates the loss for real images. The target is 1 (tf.ones_like), as we want the discriminator to classify real images as real.\n",
    "\n",
    "- fake_loss: Calculates the loss for fake images. The target is 0 (tf.zeros_like), as we want the discriminator to classify fake images as fake.\n",
    "- total_loss: The sum of real and fake losses, giving equal importance to both tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The generator loss measures how well the generator can fool the discriminator.\n",
    "\n",
    "- We use tf.ones_like(fake_output) as the target, meaning we want the generator to produce images that the discriminator classifies as real (1).\n",
    "- The loss is lower when the discriminator is more easily fooled by the generated images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our GAN, we need separate optimizers for the generator and discriminator. These optimizers are responsible for updating the model parameters during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizers\n",
    "generator_optimizer = keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We first define a train_step function that defines a single training iteration for our GAN.\n",
    "\n",
    "- It's decorated with @tf.function for improved performance through graph execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training step\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, 100])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Steps of train_step:**\n",
    "\n",
    "- Generate Noise: Create random noise as input for the generator.\n",
    "\n",
    "- Generate Fake Images: Use the generator to create fake images from the noise.\n",
    "- Discriminator Evaluation: Get the discriminator's output for both real and fake images.\n",
    "- Calculate Losses: Compute losses for both the generator and discriminator.\n",
    "- Compute Gradients: Use GradientTape to calculate gradients for both networks.\n",
    "- Update Models: Apply the calculated gradients to update the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get available devices\n",
    "def get_available_devices():\n",
    "    devices = tf.config.list_physical_devices()\n",
    "    return [d for d in devices if d.device_type in ['CPU', 'GPU']]\n",
    "\n",
    "# training loop\n",
    "def train(dataset, epochs):\n",
    "    # Get available devices\n",
    "    available_devices = get_available_devices()\n",
    "    device_type = \"GPU\" if any(d.device_type == \"GPU\" for d in available_devices) else \"CPU\"\n",
    "    \n",
    "    print(f\"Training on {device_type}\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for image_batch in dataset:\n",
    "            gen_loss, disc_loss = train_step(image_batch)\n",
    "        \n",
    "        # Print losses every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}, Gen Loss: {gen_loss:.4f}, Disc Loss: {disc_loss:.4f}\")\n",
    "        \n",
    "        # Generate and save images every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            generate_and_save_images(generator, epoch + 1, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Components of train loop:**\n",
    "\n",
    "- Epoch Loop: Iterates through the specified number of epochs.\n",
    "\n",
    "- Batch Processing: For each epoch, it processes the dataset batch by batch.\n",
    "- Training Step: Calls the train_step function for each batch, updating both the generator and discriminator.\n",
    "- Loss Reporting: Prints the generator and discriminator losses every 10 epochs, allowing us to monitor training progress.\n",
    "- Image Generation: Every 10 epochs, it generates and saves sample images using the current state of the generator. This helps visualize the improvement in image quality over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below for visualizing the progress of our GAN. It generates sample images using the current state of the generator and saves them as a grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    predictions = model(test_input, training=False)\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    # Check if directory exists, if not, create it\n",
    "    output_dir = 'data'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Save the figure in the output directory\n",
    "    plt.savefig(os.path.join(output_dir, f'image_at_epoch_{epoch:04d}.png'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set training configurations and visualize the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a fixed random seed for consistent image generation during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = tf.random.normal([16, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sets the number of training epochs to 50 and calls the train function to start the GAN training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code generates a new set of 16 random images using the trained generator and creates a 4x4 grid to display these images. It also rescales the pixel values from [-1, 1] to [0, 255] for proper display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples_to_generate = 16\n",
    "random_vector_for_generation = tf.random.normal([num_examples_to_generate, 100])\n",
    "generated_images = generator(random_vector_for_generation, training=False)\n",
    "\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "for i in range(num_examples_to_generate):\n",
    "    plt.subplot(4, 4, i+1)\n",
    "    plt.imshow(generated_images[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
