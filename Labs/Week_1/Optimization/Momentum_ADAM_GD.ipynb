{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Momentum and Adam\n",
    "\n",
    "This notebook demonstrates the implementation of a three-layer neural network and compares the performance of different optimization methods: Gradient Descent (GD), Momentum, and Adam. The neural network is trained on a two-moon-shaped dataset using various optimization techniques to find the optimal parameters that minimize the cost function and improve the accuracy of the model.\n",
    "\n",
    "### Dataset\n",
    "The dataset used in this notebook is generated using the `make_moons()` function from the `sklearn.datasets` module. The dataset consists of two classes that form two moon shapes. It is a non-linearly separable dataset, making it a suitable scenario for testing different optimization methods for training a neural network.\n",
    "\n",
    "### Activation Functions\n",
    "The neural network uses two activation functions:\n",
    "\n",
    "1. **ReLU (Rectified Linear Unit)**: The ReLU activation function is used in the hidden layers of the neural network. It allows the model to handle non-linearities efficiently and avoids the vanishing gradient problem, which can occur with sigmoid activation.\n",
    "2. **Sigmoid**: The sigmoid activation function is used in the output layer to compute the final probability of the binary classification task. It maps the input to the range (0, 1), representing the probability of the input belonging to class 1.\n",
    "\n",
    "### Optimization Methods\n",
    "\n",
    "#### 1. Gradient Descent (GD)\n",
    "Gradient Descent is a first-order optimization algorithm that updates the model's parameters in the opposite direction of the gradient of the cost function. The magnitude of the update is controlled by the learning rate. While GD is a simple and intuitive optimization method, it may suffer from slow convergence, especially for large datasets or in cases where the cost function has high curvatures.\n",
    "\n",
    "#### 2. Momentum\n",
    "Momentum is an extension of GD that introduces a moving average of the gradients to accelerate convergence. It accumulates the past gradients' information to continue moving in the same direction even when the gradients change direction frequently. This helps in faster convergence and reduces oscillations in the cost function. The momentum hyperparameter controls the influence of the past gradients.\n",
    "\n",
    "#### 3. Adam (Adaptive Moment Estimation)\n",
    "Adam is a popular optimization algorithm that combines the ideas of both Momentum and RMSprop. It uses moving averages of the past gradients and squared gradients to adapt the learning rate for each parameter. The algorithm automatically adjusts the learning rate based on the history of the gradients and their magnitudes. This adaptive learning rate makes Adam robust and efficient in practice, requiring minimal hyperparameter tuning.\n",
    "\n",
    "### Training and Evaluation\n",
    "The neural network is trained using each of the three optimization methods. For each optimization method, the model's parameters are updated iteratively over a specified number of epochs using mini-batch gradient descent. At the end of each epoch, the cost function is computed and printed to monitor the training progress. The final trained model's accuracy on the training data is also calculated and displayed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's delve into the details and theory of each optimization method along with their advantages and disadvantages.\n",
    "\n",
    "### 1. Gradient Descent (GD)\n",
    "\n",
    "**Theory**:\n",
    "Gradient Descent is a first-order optimization algorithm used to minimize the cost function of a neural network. It works by iteratively updating the model's parameters in the opposite direction of the gradient of the cost function with respect to those parameters. The gradient points in the direction of steepest ascent, so taking the opposite direction allows the algorithm to move towards the minimum of the cost function.\n",
    "\n",
    "**Algorithm**:\n",
    "1. Initialize the model's parameters randomly.\n",
    "2. Compute the gradient of the cost function with respect to each parameter.\n",
    "3. Update each parameter using the formula: `parameter = parameter - learning_rate * gradient`, where the learning_rate controls the size of the update step.\n",
    "\n",
    "**Advantages**:\n",
    "- Simple and easy to implement.\n",
    "- Can be applied to large datasets since it processes one data point at a time.\n",
    "- Can handle non-convex cost functions.\n",
    "\n",
    "**Disadvantages**:\n",
    "- Convergence can be slow, especially for large datasets or complex cost functions.\n",
    "- Sensitive to the learning rate choice; a large learning rate may lead to overshooting the minimum, while a small learning rate may result in slow convergence.\n",
    "\n",
    "### 2. Momentum\n",
    "\n",
    "**Theory**:\n",
    "Momentum is an extension of GD that aims to accelerate the convergence of the optimization process. It introduces a moving average of the past gradients to continue moving in the same direction even when the gradients change direction frequently. This helps to overcome oscillations in the cost function and speeds up convergence.\n",
    "\n",
    "**Algorithm**:\n",
    "1. Initialize the model's parameters and the velocity (initialized as zeros) for each parameter.\n",
    "2. Compute the gradient of the cost function with respect to each parameter.\n",
    "3. Update each parameter using the formula:\n",
    "   ```\n",
    "   velocity = beta * velocity + (1 - beta) * gradient\n",
    "   parameter = parameter - learning_rate * velocity\n",
    "   ```\n",
    "   where `beta` is the momentum hyperparameter.\n",
    "\n",
    "**Advantages**:\n",
    "- Accelerates convergence, especially in areas with high curvature or noisy gradients.\n",
    "- Reduces oscillations and overshooting, leading to more stable updates.\n",
    "\n",
    "**Disadvantages**:\n",
    "- Momentum may accumulate too much velocity in flat regions, making it harder to escape local minima.\n",
    "- May overshoot and oscillate when the learning rate is too large.\n",
    "\n",
    "### 3. Adam (Adaptive Moment Estimation)\n",
    "\n",
    "**Theory**:\n",
    "Adam is an adaptive learning rate optimization algorithm that combines the ideas of both Momentum and RMSprop. It uses moving averages of the past gradients and squared gradients to adapt the learning rate for each parameter. The algorithm automatically adjusts the learning rate based on the history of the gradients and their magnitudes.\n",
    "\n",
    "**Algorithm**:\n",
    "1. Initialize the model's parameters and the first and second moment estimates (initialized as zeros) for each parameter.\n",
    "2. Compute the gradient of the cost function with respect to each parameter.\n",
    "3. Update each parameter using the formula:\n",
    "   ```\n",
    "   first_moment = beta1 * first_moment + (1 - beta1) * gradient\n",
    "   second_moment = beta2 * second_moment + (1 - beta2) * gradient^2\n",
    "   first_moment_corrected = first_moment / (1 - beta1^t)\n",
    "   second_moment_corrected = second_moment / (1 - beta2^t)\n",
    "   parameter = parameter - learning_rate * first_moment_corrected / sqrt(second_moment_corrected + epsilon)\n",
    "   ```\n",
    "   where `beta1` and `beta2` are the moment hyperparameters, and `epsilon` is a small constant to prevent division by zero.\n",
    "\n",
    "**Advantages**:\n",
    "- Adaptive learning rate for each parameter, reducing the need for extensive learning rate tuning.\n",
    "- Efficient and robust in practice, suitable for a wide range of neural network architectures and cost functions.\n",
    "- Fast convergence and good generalization on various datasets.\n",
    "\n",
    "**Disadvantages**:\n",
    "- Adam may exhibit slow convergence on certain non-stationary objectives or saddle points.\n",
    "- Requires more memory to store the additional moving average parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import h5py \n",
    "import scipy.io \n",
    "import sklearn \n",
    "import sklearn.datasets\n",
    "from momentum_adam_helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Mini-Batch Gradient Descent\n",
    "\n",
    "In this section, we will explore the process of creating mini-batches from the training dataset and examine their shapes to ensure that the mini-batch creation process is working correctly.\n",
    "\n",
    "First, we load the dataset and create mini-batches using the `random_mini_batches` function with a mini-batch size of 128. We then print the shapes of the training data and the first three mini-batches to verify their correctness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y = load_dataset() #Loads the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batches = random_mini_batches(train_X, train_Y, mini_batch_size = 128 ) # Creates mini-batches from the training dataset with a specified mini-batch size.\n",
    "print (\"shape of the X_train is \" , np.shape (train_X)) # shape of the training data.\n",
    "print(\"shape of the 1st mini_batch_X: \" + str(mini_batches[0][0].shape)) # shape of the first mini-batch's input data.\n",
    "print(\"shape of the 2nd mini_batch_X: \" + str(mini_batches[1][0].shape)) # shape of the second mini-batch's input data.\n",
    "print(\"shape of the 3rd mini_batch_X: \" + str(mini_batches[2][0].shape)) # shape of the third mini-batch's input data.\n",
    "print(\"shape of the 1st mini_batch_Y: \" + str(mini_batches[0][1].shape)) # shape of the first mini-batch's output data.\n",
    "print(\"shape of the 2nd mini_batch_Y: \" + str(mini_batches[1][1].shape)) # shape of the second mini-batch's output data.\n",
    "print(\"shape of the 3rd mini_batch_Y: \" + str(mini_batches[2][1].shape)) # shape of the third mini-batch's output data.\n",
    "print(\"mini batch sanity check: \" + str(mini_batches[0][0][0][0:3])) # sanity check for the first mini-batch's input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Momentum is an optimization technique that helps accelerate the convergence of gradient descent algorithms by adding a fraction of the previous update to the current update. This method is designed to overcome the limitations of standard gradient descent, such as slow convergence and oscillations in the cost function.\n",
    "\n",
    "#### Theory\n",
    "\n",
    "Momentum works by maintaining a moving average of the gradients, which helps the algorithm to continue moving in the same direction even when the gradients change direction frequently. This moving average is controlled by a hyperparameter called the momentum coefficient (usually denoted as `beta`), which determines the influence of the past gradients on the current update.\n",
    "\n",
    "#### Algorithm\n",
    "\n",
    "1. **Initialize** the model's parameters and the velocity (initialized as zeros) for each parameter.\n",
    "2. **Compute** the gradient of the cost function with respect to each parameter.\n",
    "3. **Update** each parameter using the following formulas:\n",
    "    ```\n",
    "    velocity = beta * velocity + (1 - beta) * gradient\n",
    "    parameter = parameter - learning_rate * velocity\n",
    "    ```\n",
    "    where `beta` is the momentum hyperparameter.\n",
    "\n",
    "#### Advantages\n",
    "\n",
    "- **Accelerates convergence**: Momentum helps to speed up the convergence of the optimization process, especially in areas with high curvature or noisy gradients.\n",
    "- **Reduces oscillations**: By smoothing the updates, momentum reduces oscillations and overshooting, leading to more stable updates.\n",
    "\n",
    "#### Disadvantages\n",
    "\n",
    "- **Accumulation of velocity**: In flat regions, momentum may accumulate too much velocity, making it harder to escape local minima.\n",
    "- **Overshooting and oscillation**: When the learning rate is too large, momentum may cause overshooting and oscillation around the minimum.\n",
    "\n",
    "Momentum is a powerful technique that can significantly improve the performance of gradient descent algorithms, especially in scenarios where the cost function has high curvature or noisy gradients. By carefully tuning the momentum coefficient, it is possible to achieve faster and more stable convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_velocity(parameters):\n",
    "    L = len(parameters) // 2 # number of layers in the neural networks\n",
    "    v = {}\n",
    "    \n",
    "    # Initialize velocity\n",
    "    for l in range(L):\n",
    "        v[\"dW\" + str(l + 1)] = np.zeros_like(parameters[\"W\" + str(l+1)])\n",
    "        v[\"db\" + str(l + 1)] = np.zeros_like(parameters[\"b\" + str(l+1)])\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters_with_momentum(parameters, grads, v, beta, learning_rate) :\n",
    "\n",
    "    L = len(parameters) // 2 # number of layers in the neural networks\n",
    "    \n",
    "    # Momentum update for each parameter\n",
    "    for l in range(L):\n",
    "        \n",
    "        # compute velocities\n",
    "        v[\"dW\" + str(l + 1)] = beta * v[\"dW\" + str(l + 1)] + (1 - beta) * grads['dW' + str(l + 1)]\n",
    "        v[\"db\" + str(l + 1)] = beta * v[\"db\" + str(l + 1)] + (1 - beta) * grads['db' + str(l + 1)]\n",
    "        # update parameters\n",
    "        parameters[\"W\" + str(l + 1)] = parameters[\"W\" + str(l + 1)] - learning_rate * v[\"dW\" + str(l + 1)]\n",
    "        parameters[\"b\" + str(l + 1)] = parameters[\"b\" + str(l + 1)] - learning_rate * v[\"db\" + str(l + 1)]\n",
    "        \n",
    "    return parameters, v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## ADAM Optimizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adam (short for Adaptive Moment Estimation) is an optimization algorithm that combines the advantages of two other popular methods: AdaGrad and RMSProp. It is widely used for training deep learning models due to its efficiency and effectiveness.\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "1. **Adaptive Learning Rates**: Adam computes adaptive learning rates for each parameter. This means that each parameter has its own learning rate, which can change over time.\n",
    "\n",
    "2. **Momentum**: Adam uses the concept of momentum to accelerate the gradient vectors in the right directions, leading to faster converging.\n",
    "\n",
    "3. **Bias Correction**: Adam includes bias correction to counteract the initial bias in the moment estimates, which helps in achieving more accurate updates.\n",
    "\n",
    "## Algorithm Steps\n",
    "\n",
    "1. **Initialize Parameters**:\n",
    "  - Learning rate $\\alpha$\n",
    "  - Exponential decay rates for the moment estimates $\\beta_1$ and $\\beta_2$\n",
    "  - Small constant $\\epsilon$ to prevent division by zero\n",
    "  - Initialize first moment vector $m_t$ and second moment vector $v_t$ to zero\n",
    "\n",
    "2. **Update Rule**:\n",
    "  - Compute the gradients $g_t$ of the loss function with respect to the parameters\n",
    "  - Update biased first moment estimate:\n",
    "    $$\n",
    "    m_t = \\beta_1 \\cdot m_{t-1} + (1 - \\beta_1) \\cdot g_t\n",
    "    $$\n",
    "  - Update biased second moment estimate:\n",
    "    $$\n",
    "    v_t = \\beta_2 \\cdot v_{t-1} + (1 - \\beta_2) \\cdot g_t^2\n",
    "    $$\n",
    "  - Compute bias-corrected first moment estimate:\n",
    "    $$\n",
    "    \\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t}\n",
    "    $$\n",
    "  - Compute bias-corrected second moment estimate:\n",
    "    $$\n",
    "    \\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t}\n",
    "    $$\n",
    "  - Update parameters:\n",
    "    $$\n",
    "    \\theta_t = \\theta_{t-1} - \\alpha \\cdot \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon}\n",
    "    $$\n",
    "\n",
    "## Advantages\n",
    "\n",
    "- **Efficient Computation**: Adam is computationally efficient and has low memory requirements.\n",
    "- **Invariance to Diagonal Rescaling**: The algorithm is invariant to diagonal rescaling of the gradients, which makes it suitable for problems with large gradients.\n",
    "- **Robustness**: Adam works well in practice and is robust to noisy gradients and sparse gradients.\n",
    "\n",
    "## Common Hyperparameters\n",
    "\n",
    "- Learning rate $\\alpha$: Typically set to 0.001\n",
    "- $\\beta_1$: Typically set to 0.9\n",
    "- $\\beta_2$: Typically set to 0.999\n",
    "- $\\epsilon$: Typically set to $10^{-8}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_adam(parameters) :\n",
    "    \"\"\"\n",
    "    Initializes v and s as two python dictionaries with:\n",
    "                - keys: \"dW1\", \"db1\", ..., \"dWL\", \"dbL\" \n",
    "                - values: numpy arrays of zeros of the same shape as the corresponding gradients/parameters.\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters.\n",
    "                    parameters[\"W\" + str(l)] = Wl\n",
    "                    parameters[\"b\" + str(l)] = bl\n",
    "    \n",
    "    Returns: \n",
    "    v -- python dictionary that will contain the exponentially weighted average of the gradient.\n",
    "                    v[\"dW\" + str(l)] = ...\n",
    "                    v[\"db\" + str(l)] = ...\n",
    "    s -- python dictionary that will contain the exponentially weighted average of the squared gradient.\n",
    "                    s[\"dW\" + str(l)] = ...\n",
    "                    s[\"db\" + str(l)] = ...\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    L = len(parameters) // 2 # number of layers in the neural networks\n",
    "    v = {}\n",
    "    s = {}\n",
    "    \n",
    "    # Initialize v, s. Input: \"parameters\". Outputs: \"v, s\".\n",
    "    for l in range(L):\n",
    "        v[\"dW\" + str(l + 1)] = np.zeros_like(parameters[\"W\" + str(l + 1)])\n",
    "        v[\"db\" + str(l + 1)] = np.zeros_like(parameters[\"b\" + str(l + 1)])\n",
    "\n",
    "        s[\"dW\" + str(l+1)] = np.zeros_like(parameters[\"W\" + str(l + 1)])\n",
    "        s[\"db\" + str(l+1)] = np.zeros_like(parameters[\"b\" + str(l + 1)])\n",
    "    \n",
    "    return v, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters_with_adam(parameters, grads, v, s, t, learning_rate=0.01,\n",
    "                                beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "    \n",
    "    L = len(parameters) // 2                 # number of layers in the neural networks\n",
    "    v_corrected = {}                         # Initializing first moment estimate, python dictionary\n",
    "    s_corrected = {}                         # Initializing second moment estimate, python dictionary\n",
    "    \n",
    "    # Perform Adam update on all parameters\n",
    "    for l in range(L):\n",
    "        # Moving average of the gradients. Inputs: \"v, grads, beta1\". Output: \"v\".\n",
    "        v[\"dW\" + str(l + 1)] = beta1 * v[\"dW\" + str(l + 1)] + (1 - beta1) * grads['dW' + str(l + 1)]\n",
    "        v[\"db\" + str(l + 1)] = beta1 * v[\"db\" + str(l + 1)] + (1 - beta1) * grads['db' + str(l + 1)]\n",
    "\n",
    "        # Compute bias-corrected first moment estimate. Inputs: \"v, beta1, t\". Output: \"v_corrected\".\n",
    "        v_corrected[\"dW\" + str(l + 1)] = v[\"dW\" + str(l + 1)] / (1 - np.power(beta1, t))\n",
    "        v_corrected[\"db\" + str(l + 1)] = v[\"db\" + str(l + 1)] / (1 - np.power(beta1, t))\n",
    "\n",
    "        # Moving average of the squared gradients. Inputs: \"s, grads, beta2\". Output: \"s\".\n",
    "        s[\"dW\" + str(l + 1)] = beta2 * s[\"dW\" + str(l + 1)] + (1 - beta2) * np.power(grads['dW' + str(l + 1)], 2)\n",
    "        s[\"db\" + str(l + 1)] = beta2 * s[\"db\" + str(l + 1)] + (1 - beta2) * np.power(grads['db' + str(l + 1)], 2)\n",
    "\n",
    "        # Compute bias-corrected second raw moment estimate. Inputs: \"s, beta2, t\". Output: \"s_corrected\".\n",
    "        s_corrected[\"dW\" + str(l + 1)] = s[\"dW\" + str(l + 1)] / (1 - np.power(beta2, t))\n",
    "        s_corrected[\"db\" + str(l + 1)] = s[\"db\" + str(l + 1)] / (1 - np.power(beta2, t))\n",
    "\n",
    "        # Update parameters. Inputs: \"parameters, learning_rate, v_corrected, s_corrected, epsilon\". Output: \"parameters\".\n",
    "        parameters[\"W\" + str(l + 1)] = parameters[\"W\" + str(l + 1)] - learning_rate * v_corrected[\"dW\" + str(l + 1)] / np.sqrt(s[\"dW\" + str(l + 1)] + epsilon)\n",
    "        parameters[\"b\" + str(l + 1)] = parameters[\"b\" + str(l + 1)] - learning_rate * v_corrected[\"db\" + str(l + 1)] / np.sqrt(s[\"db\" + str(l + 1)] + epsilon)\n",
    "\n",
    "    return parameters, v, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 3-layer model\n",
    "layers_dims = [train_X.shape[0], 5, 2, 1]\n",
    "parameters = model(train_X, train_Y, layers_dims, optimizer=\"gd\")\n",
    "\n",
    "# Predict\n",
    "predictions = predict(train_X, train_Y, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 3-layer model\n",
    "layers_dims = [train_X.shape[0], 5, 2, 1]\n",
    "parameters = model(train_X, train_Y, layers_dims, beta=0.9, optimizer=\"momentum\")\n",
    "\n",
    "# Predict\n",
    "predictions = predict(train_X, train_Y, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 3-layer model\n",
    "layers_dims = [train_X.shape[0], 5, 2, 1]\n",
    "parameters = model(train_X, train_Y, layers_dims, optimizer=\"adam\")\n",
    "\n",
    "# Predict\n",
    "predictions = predict(train_X, train_Y, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "The notebook provides an insight into the effectiveness of different optimization methods in training neural networks. By comparing the performance of GD, Momentum, and Adam, we can gain a better understanding of how these algorithms handle the optimization process and improve the neural network's convergence and accuracy on non-linear datasets like the two-moon-shaped dataset used here.\n",
    "\n",
    "Each optimization method has its strengths and weaknesses, and the choice of the optimization algorithm may depend on the specific problem, dataset, and neural network architecture. While Gradient Descent is a simple baseline algorithm, Momentum and Adam often offer faster convergence and more stable updates in practice. However, Adam may require more memory due to the additional moving average parameters.\n",
    "\n",
    "It is recommended to experiment with different optimization methods and hyperparameter values to find the optimal combination that yields the best convergence and accuracy for a given neural network task. Additionally, other optimization techniques, such as Adagrad, RMSprop, and Nesterov Accelerated Gradient (NAG), are also widely used in practice and may be worth exploring for specific scenarios."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
