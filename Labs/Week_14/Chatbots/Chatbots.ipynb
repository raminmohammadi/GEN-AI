{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nmzJNBzjDGY"
      },
      "source": [
        "<h1>\n",
        "<center><b>\n",
        "Chatbots\n",
        "</b>\n",
        "</center>\n",
        "</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUmJJ1XWjI4f"
      },
      "source": [
        "# **Brief Recap**\n",
        "\n",
        "**Chatbots** are computer programs designed to simulate human conversation through text or voice interactions. These AI-powered virtual assistants have become increasingly prevalent across various industries, offering automated support and engagement for businesses and users alike.\n",
        "\n",
        "They were first introduced in the 1960s, with ELIZA being widely recognized as the first chatbot. Created by Joseph Weizenbaum at MIT in 1966, ELIZA was designed to simulate a Rogerian psychotherapist. This early chatbot used basic pattern-matching techniques to respond to user inputs, often rephrasing the user's statements as questions.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zYZGUSZjY4P"
      },
      "source": [
        "# **Architecture**\n",
        "\n",
        "\n",
        "<img src='assets/arch.png' width=500>\n",
        "\n",
        "\n",
        "**Mobile Interface**\n",
        "\n",
        "The left side shows a mobile interface with a conversation flow, displaying messages between the user and chatbot. The example conversation shows weather-related queries and responses.\n",
        "\n",
        "### **Core Components**\n",
        "\n",
        "**NLU (Natural Language Understanding)**\n",
        "- Processes user input to extract intent and entities\n",
        "- Connects directly to the mobile interface for processing incoming messages\n",
        "\n",
        "**Dialogue Management**\n",
        "- Contains a Tracker and Slots system\n",
        "- Manages conversation flow and predicts next actions based on:\n",
        "  * Previous actions\n",
        "  * Action results\n",
        "  * Slot information\n",
        "\n",
        "**Message Generator**\n",
        "- Uses predefined templates with placeholders\n",
        "- Generates appropriate responses based on the dialogue management output\n",
        "\n",
        "**Data Flow**\n",
        "1. User input from mobile device is processed by the NLU component\n",
        "2. Intent and entities are passed to the Dialogue Management system\n",
        "3. Dialogue Manager determines next actions\n",
        "4. Message Generator creates appropriate responses\n",
        "5. External API calls or database requests are made when needed\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hH7tIgaAkl6I"
      },
      "source": [
        "# **Use Cases**\n",
        "\n",
        "* **Customer Service**\n",
        "\n",
        "  Chatbots can handle up to 80% of routine customer service queries, reducing support costs by around 30%. They provide 24/7 availability, quick response times, and can efficiently route complex issues to human agents when needed.\n",
        "\n",
        "* **Sales and Marketing**\n",
        "\n",
        "  Chatbots assist in lead generation, nurturing prospects through the sales funnel, and providing personalized product recommendations5. They can engage customers proactively, offering immediate support upon a user's site visit.\n",
        "\n",
        "* **Internal Employee Support**\n",
        "\n",
        "  Organizations use chatbots to assist employees with tasks such as scheduling meetings, answering HR-related questions, and providing quick access to company information.\n",
        "\n",
        "* **Healthcare**\n",
        "\n",
        "  In the healthcare sector, chatbots help patients schedule appointments, find healthcare providers, and offer basic medical information. They can also assist in medication reminders and tracking health goals."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHDxmG_tluuu"
      },
      "source": [
        "# **Implementation 🤖💬**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYPAy92-tFPY"
      },
      "source": [
        "## **Using plain Python**\n",
        "\n",
        "Here's a simple implementation of a chatbot using Python. This demonstration follows the basic chatbot architecture with\n",
        "* NLU\n",
        "* Dialogue management\n",
        "* Response generation components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ds4CFJjLmchX"
      },
      "source": [
        "1. **SimpleChatbot Class**:\n",
        "\n",
        "* **`__init__(self)`**: This is the constructor, initializing the chatbot's core components:\n",
        "\n",
        "  * `intents`: A dictionary mapping intents (like 'greeting', 'weather', 'farewell') to lists of keywords that trigger those intents.\n",
        "  * `responses`: A dictionary mapping intents to corresponding responses. It also includes a default 'unknown' response for unmatched inputs.\n",
        "* **`nlu_component(self, user_input)`**: This function acts as the Natural Language Understanding (NLU) component.\n",
        "\n",
        "  * It takes user input, converts it to lowercase, and checks for the presence of keywords associated with each intent.\n",
        "  * If an intent is identified, it returns a dictionary with the detected intent.\n",
        "  * If no intent is found, it returns 'unknown' as the intent.\n",
        "* **`generate_response(self, intent)`**: This function is the response generation component.\n",
        "\n",
        "  * It takes the detected intent and retrieves the corresponding response from the responses dictionary.\n",
        "  * If the intent is not found in the dictionary, it returns the default 'unknown' response.\n",
        "* **`process_input(self, user_input)`**: This function orchestrates the chatbot's interaction.\n",
        "\n",
        "  * It takes user input, passes it to the NLU component to get the intent, and then uses the generate_response function to get the appropriate response.\n",
        "  * Finally, it returns the generated response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qevVqBZQm5AL"
      },
      "outputs": [],
      "source": [
        "from typing import Dict\n",
        "\n",
        "\n",
        "class SimpleChatbot:\n",
        "    def __init__(self):\n",
        "        self.intents = {\n",
        "            'greeting': ['hello', 'hi', 'hey'],\n",
        "            'weather': ['weather', 'forecast', 'temperature'],\n",
        "            'farewell': ['bye', 'goodbye', 'see you']\n",
        "        }\n",
        "\n",
        "        self.responses = {\n",
        "            'greeting': 'Hello! How can I help you today?',\n",
        "            'weather': 'The weather today is sunny with a high of 75°F.',\n",
        "            'farewell': 'Goodbye! Have a great day!',\n",
        "            'unknown': 'I apologize, I did not understand that.'\n",
        "        }\n",
        "\n",
        "    def nlu_component(self, user_input: str) -> Dict[str, str]:\n",
        "        # Convert input to lowercase for better matching\n",
        "        user_input = user_input.lower()\n",
        "\n",
        "        # Detect intent based on keywords\n",
        "        for intent, keywords in self.intents.items():\n",
        "            if any(keyword in user_input for keyword in keywords):\n",
        "                return {'intent': intent}\n",
        "        return {'intent': 'unknown'}\n",
        "\n",
        "    def generate_response(self, intent: str) -> str:\n",
        "        return self.responses.get(intent, self.responses['unknown'])\n",
        "\n",
        "    def process_input(self, user_input: str) -> str:\n",
        "        # Get intent from NLU component\n",
        "        result = self.nlu_component(user_input)\n",
        "        # Generate appropriate response\n",
        "        return self.generate_response(result['intent'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDCd4EV_m8Gl"
      },
      "source": [
        "**2. `chat()` Function:**\n",
        "\n",
        "* This function creates an instance of the SimpleChatbot class.\n",
        "* It starts a loop that prompts the user for input, processes it using the chatbot's process_input method, and prints the chatbot's response.\n",
        "* The loop continues until the user types 'bye', triggering the chatbot to respond with a farewell message and exit the loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Q7cQ2qM0k5CM"
      },
      "outputs": [],
      "source": [
        "\n",
        "def chat():\n",
        "    chatbot = SimpleChatbot()\n",
        "    print(\"Chatbot: Hi! I'm a simple chatbot. Type 'bye' to exit.\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == 'bye':\n",
        "            print(\"Chatbot:\", chatbot.process_input('bye'))\n",
        "            break\n",
        "        response = chatbot.process_input(user_input)\n",
        "        print(\"Chatbot:\", response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBdLGaVuk5As",
        "outputId": "19960b96-e80a-46f8-cb7f-0004db12abb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chatbot: Hi! I'm a simple chatbot. Type 'bye' to exit.\n",
            "You: Hi\n",
            "Chatbot: Hello! How can I help you today?\n",
            "You: How is the weather today?\n",
            "Chatbot: The weather today is sunny with a high of 75°F.\n",
            "You: Bye\n",
            "Chatbot: Goodbye! Have a great day!\n"
          ]
        }
      ],
      "source": [
        "chat()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBKLTXSNnEx4"
      },
      "source": [
        "**In essence,**\n",
        "\n",
        "This implementation showcases a simple rule-based chatbot. It relies on predefined keywords and responses to handle specific user inputs. More advanced chatbots would incorporate machine learning techniques for intent recognition and response generation, enabling more natural and flexible conversations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCXi0FJMqLHX"
      },
      "source": [
        "## **Using OpenAI API**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgIu0PVs0v8G"
      },
      "source": [
        "**1. Initializing the `OpenAIBot` class**\n",
        "\n",
        "* `__init__(self, engine)`: This is the constructor. It initializes the conversation with a system message to set the behavior of the assistant. It also stores the engine (the specific OpenAI model to use).\n",
        "* `add_message(self, role, content)`: This method adds a message to the conversation history, specifying the role (either \"system\", \"user\", or \"assistant\") and the message content.\n",
        "* `generate_response(self, prompt)`: This is the core method for generating responses. It adds the user's prompt to the conversation, sends the entire conversation to the OpenAI API, extracts the assistant's response, adds it to the conversation history, and returns the response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Ze6_PBUKk46P"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "open_ai_api_key = \"YOUR_API_KEY\"\n",
        "class OpenAIBot:\n",
        "    def __init__(self, engine):\n",
        "        # Initialize conversation with a system message\n",
        "        self.conversation = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n",
        "        self.engine = engine\n",
        "    def add_message(self, role, content):\n",
        "        # Adds a message to the conversation.\n",
        "        self.conversation.append({\"role\": role, \"content\": content})\n",
        "    def generate_response(self, prompt):\n",
        "        # Add user prompt to conversation\n",
        "        self.add_message(\"user\", prompt)\n",
        "\n",
        "        # Make a request to the API using the chat-based endpoint with conversation context\n",
        "        # Updated to use client.chat.completions.create()\n",
        "        response = openai.Client(api_key=open_ai_api_key).chat.completions.create(\n",
        "            model=self.engine,\n",
        "            messages=self.conversation\n",
        "        )\n",
        "\n",
        "        # Extract the response\n",
        "        assistant_response = response['choices'][0]['message']['content'].strip()\n",
        "        # Add assistant response to conversation\n",
        "        self.add_message(\"assistant\", assistant_response)\n",
        "        # Return the response\n",
        "        return assistant_response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxqe5UJn0_yP"
      },
      "source": [
        "**2. Creating and using the Chatbot**\n",
        "\n",
        "* This creates an instance of the OpenAIBot class, using the specified engine.\n",
        "* It enters a loop that continuously prompts the user for input, generates a response from the chatbot, and prints the response. The loop terminates when the user types \"**END CHAT**\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWPONOL8k44N"
      },
      "outputs": [],
      "source": [
        "\n",
        "'''Choose whichever model you want to use'''\n",
        "engine = [\"gpt-3.5-turbo\", \"gpt-3.5-turbo-16k\", \"gpt-4\"]\n",
        "\n",
        "'''\n",
        "Creating the ChatBot\n",
        "Each Object of \"OpenAIBot(engine)\" will retain the conversation history and context unless the session is terminated\n",
        "'''\n",
        "chatbot = OpenAIBot(engine[0])\n",
        "\n",
        "while True:\n",
        "    # Get Prompt from User\n",
        "    prompt = input()\n",
        "\n",
        "    # User can stop the chat by sending 'End Chat' as a Prompt\n",
        "    if prompt.upper() == 'END CHAT':\n",
        "        break\n",
        "\n",
        "    # Generate and Print the Response from ChatBot\n",
        "    response = chatbot.generate_response(prompt)\n",
        "    print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P16cbKrW1KSk"
      },
      "source": [
        "**In essence,**\n",
        "\n",
        "We leveraged OpenAI's API to build a conversational chatbot. It maintains a conversation history to provide context to the language model, enabling more coherent and interactive dialogues. Remember to replace \"YOUR_API_KEY\" with your actual API key from OpenAI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKMDe7GAxEEU"
      },
      "source": [
        "## **Using LangChain🦜⛓️‍💥**\n",
        "This section demonstrates how to build a chatbot using the LangChain library, which simplifies the process of interacting with large language models (LLMs) like those from OpenAI.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cef1BSSQyyn9"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rE3OquwypIE"
      },
      "source": [
        "* **`langchain_openai`**: Provides tools for using OpenAI's models within LangChain.\n",
        "* **`langchain_core.messages`**: Defines different message types used in chatbot conversations (Human, AI, System).\n",
        "* **`langchain_core.prompts`**: Offers functionalities to create and manage prompts for the language model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFptYIamy0Pm"
      },
      "source": [
        "**1. Initializing the Chat Model**\n",
        "\n",
        "Lets initialize an instance of the `ChatOpenAI` class, which connects to OpenAI's chat models using your API key.\n",
        "\n",
        "```python\n",
        "\"gpt-3.5-turbo\"     --> engine[0]\n",
        "\"gpt-3.5-turbo-16k\" --> engine[1]\n",
        "\"gpt-4\"             --> engine[2]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "-9UoY09ck40n"
      },
      "outputs": [],
      "source": [
        "# Initialize the chat model\n",
        "model = ChatOpenAI(api_key=open_ai_api_key, model=engine[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAUOqd9uzm0e"
      },
      "source": [
        "**2. Creating the Prompt Template**\n",
        "\n",
        "A prompt template is defined using ChatPromptTemplate. This template structures the conversation by specifying system and user messages. The system message sets the initial context for the AI, while {input} is a placeholder for the actual user input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66obUUGSzmfX"
      },
      "outputs": [],
      "source": [
        "# Create a prompt template with proper message formatting\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful and friendly AI assistant.\"),\n",
        "    (\"human\", \"{input}\")\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Np0OLRUtzzlL"
      },
      "source": [
        "**3. The `chat()` function**\n",
        "\n",
        "* This function manages the main chatbot loop.\n",
        "* It takes user input and formats it using the prompt template.\n",
        "* It then uses the `model.invoke()` method to send the formatted prompt to the AI model and receive a response.\n",
        "* Finally, it prints the chatbot's response and appends the interaction to the `chat_history`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NSpRrNejCpk"
      },
      "outputs": [],
      "source": [
        "def chat():\n",
        "    print(\"Chatbot: Hello! How can I help you today? (Type 'quit' to exit)\")\n",
        "\n",
        "    # Initialize chat history\n",
        "    chat_history = []\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "\n",
        "        if user_input.lower() == 'quit':\n",
        "            print(\"Chatbot: Goodbye!\")\n",
        "            break\n",
        "\n",
        "        # Format the messages correctly\n",
        "        formatted_prompt = prompt.format_messages(input=user_input)\n",
        "\n",
        "        # Get response from model\n",
        "        response = model.invoke(formatted_prompt)\n",
        "\n",
        "        # Store messages in chat history\n",
        "        chat_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "        chat_history.append({\"role\": \"assistant\", \"content\": response.content})\n",
        "\n",
        "        print(f\"Chatbot: {response.content}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    chat()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ka_qbd401bSi"
      },
      "source": [
        "**In essence,**\n",
        "\n",
        "LangChain makes chatbot development more organized and maintainable by abstracting away complexities and providing tools for structured interactions with LLMs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kFdbLMsxOqv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGBu0xRIxOo3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZqZqbWDxOlJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
