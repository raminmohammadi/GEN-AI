{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Databases with Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pinecone is a fully managed vector database service that makes it easy to build high-performance vector search applications. \n",
    "\n",
    "- Unlike traditional databases that store and query structured data, Pinecone is specifically designed for similarity search in high-dimensional vector spaces. \n",
    "\n",
    "- This makes it particularly well-suited for applications in machine learning, natural language processing, computer vision, and recommendation systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Pinecone?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pinecone offers several advantages that make it an excellent choice for vector search applications:\n",
    "\n",
    "1. Managed Infrastructure: Pinecone handles all the infrastructure management, scaling, and optimization, allowing developers to focus on building applications.\n",
    "\n",
    "2. Real-time Updates: Unlike some vector databases that require periodic rebuilding of indices, Pinecone supports real-time updates to your vector data.\n",
    "\n",
    "3. Hybrid Search: Combine vector similarity search with traditional metadata filtering for more precise results.\n",
    "\n",
    "4. Enterprise Features: Built-in security features, automatic backups, and high availability make it suitable for production deployments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started with Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Pinecone Account and Obtaining API Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can start using Pinecone, we need to create an account and obtain our API credentials. Here's how to do it:\n",
    "\n",
    "1. First, visit the Pinecone website (https://www.pinecone.io/) and click on the \"Start Free\" button.\n",
    "\n",
    "2. You'll be prompted to create an account. You can sign up using:\n",
    "   - Your email address\n",
    "   - GitHub account\n",
    "   - Google account\n",
    "\n",
    "3. After creating your account, you'll be taken to the Pinecone Console. This is where you'll manage your indexes and API keys.\n",
    "\n",
    "4. To create an API key:\n",
    "   - Navigate to the API Keys section in the console\n",
    "   - Click on \"Create API Key\"\n",
    "   - Give your key a meaningful name (e.g., \"development-key\" or \"tutorial-key\")\n",
    "   - Set the appropriate permissions (read/write)\n",
    "   - Copy and save your API key immediately - you won't be able to see it again!\n",
    "\n",
    "5. Make note of your environment. You can find this in the console next to your API key. It will look something like \"us-east1-gcp\" or \"us-west1-aws\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important Security Considerations:\n",
    "- Never commit your API key to version control\n",
    "- Use environment variables or secure secret management systems\n",
    "- Rotate your keys periodically\n",
    "- Create separate keys for development and production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how to properly manage your API key in your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['PINECONE_API_KEY'] = \"FILL_IN_YOUR_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get API key from environment variable\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `.env` file in your project directory:\n",
    "\n",
    "\n",
    "```plaintext\n",
    "PINECONE_API_KEY=your-api-key-here\n",
    "```\n",
    "\n",
    "Make sure to add `.env` to your `.gitignore` file:\n",
    "```plaintext\n",
    "# .gitignore\n",
    ".env\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's import our dependencies and initialize Pinecone:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List, Dict\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#Define index name\n",
    "index_name = \"sentence-embeddings\"\n",
    "pinecone_env = \"us-east-1\"  # You can change this to your preferred region\n",
    "\n",
    "# Initialize Pinecone\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Vector Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create an index to store our vectors. Pinecone indexes require configuration based on your specific use case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create index if it doesn't exist\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    # Create a serverless index\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,  # feature dimension\n",
    "        metric='cosine',\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws',\n",
    "            region=pinecone_env  # You can change this to your preferred region\n",
    "        )\n",
    "    )\n",
    "    print(f\"Created new index: {index_name}\")\n",
    "else:\n",
    "    print(f\"Using existing index: {index_name}\")\n",
    "\n",
    "# Get the index\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Processing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a simple document processing pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "\n",
    "class Document:\n",
    "    def __init__(self, title: str, content: str, metadata: Dict = None):\n",
    "        self.title = title\n",
    "        self.content = content\n",
    "        self.metadata = metadata or {}\n",
    "        \n",
    "    def to_text(self) -> str:\n",
    "        return f\"{self.title} {self.content}\"\n",
    "\n",
    "def process_documents(documents: List[Document], \n",
    "                     model: SentenceTransformer) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Process documents into vectors and prepare them for Pinecone indexing.\n",
    "    \"\"\"\n",
    "    processed_docs = []\n",
    "    \n",
    "    for i, doc in enumerate(tqdm(documents)):\n",
    "        # Generate vector embedding\n",
    "        vector = model.encode(doc.to_text())\n",
    "        \n",
    "        # Create the record\n",
    "        record = {\n",
    "            'id': f'doc_{i}',\n",
    "            'values': vector.tolist(),\n",
    "            'metadata': {\n",
    "                'title': doc.title,\n",
    "                'content': doc.content,\n",
    "                **doc.metadata\n",
    "            }\n",
    "        }\n",
    "        processed_docs.append(record)\n",
    "    \n",
    "    return processed_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a function to upload our vectors to Pinecone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_documents(index: pinecone.Index, \n",
    "                   processed_docs: List[Dict], \n",
    "                   batch_size: int = 100):\n",
    "    \"\"\"\n",
    "    Upload document vectors to Pinecone in batches.\n",
    "    \"\"\"\n",
    "    total_docs = len(processed_docs)\n",
    "    \n",
    "    for i in tqdm(range(0, total_docs, batch_size)):\n",
    "        batch = processed_docs[i:min(i + batch_size, total_docs)]\n",
    "        index.upsert(vectors=batch)\n",
    "\n",
    "# Example usage:\n",
    "sample_docs = [\n",
    "    Document(\n",
    "        title=\"Introduction to Machine Learning\",\n",
    "        content=\"Machine learning is a subset of artificial intelligence...\",\n",
    "        metadata={\"category\": \"technology\", \"date\": \"2024-01-01\"}\n",
    "    ),\n",
    "    # Add more documents...\n",
    "]\n",
    "\n",
    "# Initialize the embedding model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Process and index documents\n",
    "processed_docs = process_documents(sample_docs, model)\n",
    "index_documents(index, processed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Semantic Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a search function that uses Pinecone's hybrid search capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(\n",
    "    query: str,\n",
    "    index: pinecone.Index,\n",
    "    model: SentenceTransformer,\n",
    "    top_k: int = 5,\n",
    "    metadata_filter: Dict = None\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Perform semantic search with optional metadata filtering.\n",
    "    \"\"\"\n",
    "    # Generate query vector\n",
    "    query_vector = model.encode(query).tolist()\n",
    "    \n",
    "    # Perform the search\n",
    "    search_results = index.query(\n",
    "        vector=query_vector,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True,\n",
    "        filter=metadata_filter\n",
    "    )\n",
    "    \n",
    "    # Format results\n",
    "    formatted_results = []\n",
    "    for match in search_results['matches']:\n",
    "        result = {\n",
    "            'title': match['metadata']['title'],\n",
    "            'content': match['metadata']['content'][:200] + \"...\",\n",
    "            'score': match['score'],\n",
    "            'metadata': {k:v for k,v in match['metadata'].items() \n",
    "                        if k not in ['title', 'content']}\n",
    "        }\n",
    "        formatted_results.append(result)\n",
    "    \n",
    "    return formatted_results\n",
    "\n",
    "# Example usage:\n",
    "results = semantic_search(\n",
    "    query=\"what is machine learning?\",\n",
    "    index=index,\n",
    "    model=model,\n",
    "    metadata_filter={\"category\": \"technology\"}\n",
    ")\n",
    "\n",
    "# Display results\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"\\nResult {i}:\")\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Preview: {result['content']}\")\n",
    "    print(f\"Score: {result['score']}\")\n",
    "    print(f\"Metadata: {result['metadata']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Namespace Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pinecone supports namespaces to partition your vector data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_namespace(\n",
    "    index: pinecone.Index,\n",
    "    namespace: str,\n",
    "    vectors: List[Dict]\n",
    "):\n",
    "    \"\"\"\n",
    "    Index vectors to a specific namespace.\n",
    "    \"\"\"\n",
    "    index.upsert(\n",
    "        vectors=vectors,\n",
    "        namespace=namespace\n",
    "    )\n",
    "\n",
    "def search_in_namespace(\n",
    "    index: pinecone.Index,\n",
    "    namespace: str,\n",
    "    query_vector: List[float],\n",
    "    top_k: int = 5\n",
    "):\n",
    "    \"\"\"\n",
    "    Search within a specific namespace.\n",
    "    \"\"\"\n",
    "    return index.query(\n",
    "        vector=query_vector,\n",
    "        namespace=namespace,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices and Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Batch Processing: Always batch your upserts to optimize performance.\n",
    "2. Index Configuration: Choose appropriate pod types and sizes based on your data volume and query patterns.\n",
    "3. Vector Dimension: Use lower-dimensional embeddings when possible to reduce storage and improve query speed.\n",
    "4. Metadata Design: Keep metadata fields minimal and relevant to your search needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to clean up resources when you're done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the index when you're finished\n",
    "pc.delete_index(index_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTES:**\n",
    "\n",
    "This notebook demonstrates the fundamental concepts of working with Pinecone for vector search applications. You can extend these examples based on your specific use case, whether it's document similarity, recommendation systems, or any other vector search application.\n",
    "\n",
    "Remember to replace the API key and environment variables with your actual Pinecone credentials when using this code. Also, consider the pricing implications of your index configuration and usage patterns in production environments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
